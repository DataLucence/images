{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "Hypothesis: Treatment with drug Y will cause a decrease in the total amount of protein Y. You have saved the control dataset as \"no_drug.tif\" and the drugged cell dataset as \"drug.tif\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some boilerplate code to make it easier to access useful libraries, and to make it easier to visualize data in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark', rc={'image.cmap':'inferno'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import an image file and associated metadata as we learnt yesterday!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "data_drug = imread(\"../data/drug.tif\")\n",
    "data_nodrug = imread(\"../data/no_drug.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/drug.json', mode='r') as f_drug:\n",
    "    meta_drug = json.load(f_drug)\n",
    "with open('../data/no_drug.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)\n",
    "\n",
    "drug_stack = {}\n",
    "nodrug_stack = {}\n",
    "for idx, channel in enumerate(meta_drug['channels']):\n",
    "    drug_stack[channel] = data_drug[:,:,idx]\n",
    "    nodrug_stack[channel] = data_nodrug[:,:,idx]    \n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(nodrug_stack[\"actin\"])\n",
    "ax[1].imshow(nodrug_stack['nucleus'])\n",
    "ax[2].imshow(nodrug_stack[\"your_fav_protein\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(drug_stack[\"actin\"])\n",
    "ax[1].imshow(drug_stack['nucleus'])\n",
    "ax[2].imshow(drug_stack[\"your_fav_protein\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing pipelines: an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have images of fixed cells in three channels -- cell bodies labeled with an actin stain, nuclei labeled with DAPI, and a third protein \"your_fav_protein\" that responds to drug treatment. Just by looking at the images it seems like the protein is shifting from the nuclei to the cell body once the drug is applied (always visualize your intermediates!), but it is unclear if the drug treatment changes the total amount of protein per cell as well.\n",
    "\n",
    "To address these questions, you will need to do the following --\n",
    "\n",
    "1. Make a mask of the actin channel to identify pixels within the cell bodies\n",
    "2. Make a mask of the nuclear channel to identify pixels within the nucleus\n",
    "3. Determine the signal coming from *your favorite protein* within these regions of interest. \n",
    "\n",
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "Tomorrow (Day 4), we will cover how to design your image processing pipeline to preserve the quantitative integrity of the image data when we pre-process the your_fav_protein image. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual determination of image background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**in retrospect, it's really hard to do this lesson without a discussion of sources (and distributions) of noise and background in an image. What looks like background can come from read or thermal/dark noise, sample autofluorescence, or from out-of-focus light. The point here is that it is added on top of the true signal from your localized fluorophores, and so should be subtracted off for quantitative analysis.\n",
    "\n",
    "**an approach where we add noise back in to the dataset would be really good here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background Subtraction can be a powerful way to remove unwanted signal from image data. For example, if the laser intensity was set too high (and as long as your image is not saturated, because then it's back to the microscope with you!), you can get rid of the excess signals by subtracting a number (called a \"threshold\") from every pixel in the image. There are many ways to find this number, but let's quickly check the data type of our image and make sure we're working on 16-bit unsigned integers as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drug_stack['actin'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, great! Now let's take a small slice of our image, so it's easier to visualize, and start subtracting a constant threshold from that slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "\n",
    "original_slice = drug_stack[\"actin\"][500:600,50:150]\n",
    "top = original_slice.max()\n",
    "\n",
    "@interactive\n",
    "def manual_background_subtract(bg=(0, top * 0.3, 10)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(9, 4))\n",
    "    bgs = original_slice.astype('int32') - bg \n",
    "    ax[0].imshow(original_slice, vmin=0, vmax=top * 0.8)\n",
    "    ax[1].imshow(bgs, vmin=0, vmax=top * 0.8)\n",
    "    ax[2].imshow(bgs[60:80,60:80], vmin=0, vmax=top * 0.01)\n",
    "manual_background_subtract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with this slider and see what happens as you subtract larger and larger thresholds from the image. Note that in the first two panels the background already appears to be *0*, but if you adjust the contrast and zoom in (panel 3) the background and noise become readily visible.\n",
    "\n",
    "How might you determine the background in the precence of noise? \n",
    "**answer: you don't**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think \"eyeballing it\" is a good way to figure out what the threshold should be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated detection of background threshold using Otsu's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobuyuki Otsu proposed a method (now very widely used) to detect thresholds. Simply put, the idea is to assume that background pixels (unwanted), and foreground pixels (your signal) will follow a bimodal distribution, i.e. that all the background pixels will be a well defined group on a histogram, which will be different from another well defined group that will be brighter, and is the signal that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "thresh = filters.threshold_otsu(drug_stack[\"actin\"])\n",
    "#thresh2 = filters.threshold_otsu(nodrug_stack[\"actin\"])\n",
    "print(\"drug threshold is:\", thresh)\n",
    "#print(\"no drug threshold is:\", thresh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mr. Otsu thinks this is the magic number for this *slice* of the image. Let's just take a quick look at the histogram to see if the background pixels and foreground pixels are as clearly delineated as Mr. Otsu expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(nodrug_stack[\"actin\"].flatten(), hist_kws={'log': True}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the saturation peak. Do you think this may be influencing the quality of the threshold? Repeat the threshold determination by excluding the saturationed pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh_no_sat = filters.threshold_otsu(drug_stack[\"actin\"][drug_stack[\"actin\"] < 2**16 - 1])\n",
    "bg = drug_stack[\"actin\"][drug_stack[\"actin\"]<thresh_no_sat].mean()\n",
    "Otsu_bgs_slice = original_slice - bg\n",
    "#thresh2_no_sat = filters.threshold_otsu(nodrug_stack[\"actin\"][nodrug_stack[\"actin\"] < 2**16 - 1])\n",
    "print(\"drug threshold is:\", thresh_no_sat)\n",
    "print(\"drug background is:\", bg)\n",
    "#print(\"no drug threshold is:\", thresh2_no_sat)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "ax[1].imshow(Otsu_bgs_slice[60:80,60:80], vmin=0, vmax=2**16 * 0.1  )\n",
    "\n",
    "ax[0].distplot(drug_stack[\"actin\"].flatten(), hist_kws={'log': True}, kde=False)\n",
    "plt.axvline(thresh_no_sat, ls='--', lw=2, c='b') #marks the saturation-corrected threshold\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r') #marks the original threshold\n",
    "plt.axvline(bg, ls='--', lw=2, c='g') #marks the background determined from the thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**to be fixed: in my rendering, the histogram was flipped up side down**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Masks for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're trying to identify objects, you typically want to make a mask. A Mask is exactly what it sounds like. It's something that allows you to work on only some pixels and not others. Here, we'll essentially take most of the information in our 16-bit image, and throw it away (!). We will convert the image to **binary**, essentially reducing the bit depth to 1, and in the process, replace all the pixels below the threshold to zero, and all the pixels above the threshold to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works in practice. We can ask the computer to return every pixels that's above the threshold, and take a look at a small portion of what it spits out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a mask using thresh as the threshold\n",
    "above_thresh = original_slice > thresh\n",
    "above_thresh[45:50,45:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that above_thresh is a *boolean array*. This is a series of \"True\" or \"False\" statements, one for every pixel in the image, where True implies the pixel is above the threshold, and False implies it's below the threshold. You'll notice that we can't actually do any math with True or False statements (unless you're a philosopher), so we'll replace these with ones and zeros. We can write a \"function\" to do this easily every time with one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_image(img, thresh):\n",
    "    output = img.copy()\n",
    "    output[img < thresh] = 0\n",
    "    output[img >= thresh] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the function will take two \"arguments\", the image, and the threshold, and output a mask the same size as the image, but consisting of ones and zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_slice = threshold_image(original_slice,thresh)\n",
    "masked_slice.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So now we've converted our image slice into an integer array of ones and zeros. Let's take a quick second to see what this does to the entire image. Notice how we need to calculate the otsu threshold again for the whole image, because the *thresh* variable contains the threshold calculated with just the *original_slice*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_image = drug_stack[\"actin\"]\n",
    "masked_whole_image = threshold_image(whole_image, filters.threshold_otsu(whole_image))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(masked_whole_image)\n",
    "ax[1].imshow(masked_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the cell bodies have many \"holes\" in them? Even isolated pixels just hanging out where they clearly don't belong. The impudence! What can we do to get rid of them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Shot Noise from your Image -- Median Fitering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better at object detection, we can leverage various properties of the pixels. With time, you will be able to leverage pretty much any property you can articulate, but for now, let's use the idea that the pixels that are hanging out in the wrong places are surrounded by other pixels that are properly classified. Let's make them listen to their neighbours. There are many ways to do this. One useful method to know is called Median filtering. It goes pixel by pixel, and replaces each pixel with the median of its surroundings. Let's load our image slice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import median_filter\n",
    "plt.imshow(original_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tech tip: These images were taken with a confocal microscope, which uses a PMT (photomultiplier tube) with high sensitivity. However, because this detector operates in a low-photon regime, shot noise (Poisson distributed) can add substantial deviation of pixel values from the local fluorescence intensities they represent. Shot noise is commonly removed with the median filter, although other rank filters exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "\n",
    "@interactive\n",
    "def apply_filter(size=(1, 21)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    \n",
    "    # Here we implement the median filtering\n",
    "    filtered = median_filter(original_slice, size=size)\n",
    "                             \n",
    "    ax[0].imshow(original_slice)\n",
    "    ax[1].imshow(filtered)\n",
    "    dif_img = filtered.astype('int') - original_slice.astype('int')\n",
    "    \n",
    "    extreme = 10000\n",
    "    im = ax[2].imshow(dif_img, vmin=-extreme, vmax=extreme, cmap='coolwarm')\n",
    "    \n",
    "    print(\"total difference in image =\" + str(np.mean(dif_img)) + \" arbitrary units\")\n",
    "    print(\"percent change =\" + str(np.mean(dif_img)/100) + \"%\") \n",
    "apply_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that the size of the filter determines the value of the median value of the pixels in the output. That means, the larger the filter size, the more neighbours the filter will look at, before deciding what the new pixel value should be. A good rule of thumb when determining an appropriate filter size is that it should be the smallest filter that sufficiently flattens the visible noise in the background. Many of these operations do not have well-accepted statistical tests for determing the appropriate parameters, so care needs to be taken to record and reproduce processing steps with the same parameters. \n",
    "\n",
    "Let's choose a filter size of 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_slice = median_filter(original_slice, size=3)\n",
    "filtered_image = median_filter(whole_image, size=3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(filtered_image)\n",
    "ax[1].imshow(filtered_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the filtering affects our mask, and compare to the mask we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_filtered_slice = threshold_image(filtered_slice, filters.threshold_otsu(filtered_slice))\n",
    "masked_filtered_image = threshold_image(filtered_image, filters.threshold_otsu(filtered_image))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_image)\n",
    "ax[1].imshow(masked_slice)\n",
    "ax[2].imshow(masked_filtered_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but still not perfect! What do you think would happen if we tried to apply the mask before the filter? (this could be an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_masked_slice = median_filter(masked_slice, size=3)\n",
    "filtered_masked_image = median_filter(masked_whole_image, size=3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_slice)\n",
    "ax[1].imshow(filtered_masked_slice)\n",
    "ax[2].imshow(masked_filtered_slice - filtered_masked_slice, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does doing this not make sense? (this leads to discussion of morphological operations...)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
