{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "Hypothesis: Treatment with drug Y will cause a decrease in the total amount of protein Y. You have saved the control dataset as \"no_drug.tif\" and the drugged cell dataset as \"drug.tif\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some boilerplate code to make it easier to access useful libraries, and to make it easier to visualize data in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark', rc={'image.cmap':'inferno'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import an image file and associated metadata as we learnt yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "#THE real data to be imported in the class is commented out for now because files are currently too large for github\n",
    "\n",
    "data_drug = imread(\"../data/confocal_drug_panel/drugA.tif\")\n",
    "# data_nodrug = imread(\"../data/confocal_drug_panel/DMSO.tif\")\n",
    "data_nodrug = imread(\"../data/confocal_drug_panel/temp_DMSO.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/confocal_drug_panel/DMSO_metadata.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)\n",
    "\n",
    "drug_slice = {}\n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    drug_slice[channel] = data_drug[4,:,:,idx]\n",
    "    nodrug_slice[channel] = data_nodrug #[4,:,:,idx]    #add in the indexing when read in full dataset\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(nodrug_slice[\"actin\"])\n",
    "ax[1].imshow(nodrug_slice['nucleus'])\n",
    "ax[2].imshow(nodrug_slice[\"your_fav_protein\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(drug_slice[\"actin\"])\n",
    "ax[1].imshow(drug_slice['nucleus'])\n",
    "ax[2].imshow(drug_slice[\"your_fav_protein\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing: a motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have images of fixed cells in three channels -- cell bodies labeled with an actin stain, nuclei labeled with DAPI, and a third protein \"your_fav_protein\" that responds to drug treatment. Just by looking at the images it seems like the protein is shifting from the nuclei to the cell body once the drug is applied (always visualize your intermediates!), but it is unclear if the drug treatment changes the total amount of protein per cell as well.\n",
    "\n",
    "To address these questions, you will need to do the following --\n",
    "\n",
    "1. Make a mask of the actin channel to identify pixels within the cell bodies\n",
    "2. Make a mask of the nuclear channel to identify pixels within the nucleus\n",
    "3. Determine the signal coming from *your favorite protein* within these regions of interest. \n",
    "\n",
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "Tomorrow (Day 4), we will cover how to design your image processing pipeline to deal with some trickier problems, such as quantifying fluorescence in the ROIs determined here. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making masks to localize cell bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodrug_slice['actin'].dtype\n",
    "data = nodrug_slice['actin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find an appropriate threshold that defines the cell bodies accurately across the image using the sliding bar.**\n",
    "First, view the image more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters to adjust\n",
    "minX1 = 700 #crop edges for a cell in the center of field of view\n",
    "minY1 = 900\n",
    "minX2 = 1200 #crop edges for cell at the edge of the field of view\n",
    "minY2 = 1800\n",
    "crop_size = 200 #pix\n",
    "image_view_thresh = 0.1\n",
    "\n",
    "#run\n",
    "maxX1 = minX1 + crop_size\n",
    "maxY1 = minY1 + crop_size\n",
    "maxX2 = minX2 + crop_size\n",
    "maxY2 = minY2 + crop_size\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], vmin=0, vmax=top)\n",
    "ax[0].imshow(data, vmin=0, vmax=top)\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], vmin=0, vmax=top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine using the sliding bar which threshold gives the best mask across the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_masks(thresh=(0, data.max() * 0.1, 20)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "    mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "    mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "    mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "    ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "    ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated detection of foreground using Otsu's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobuyuki Otsu proposed a method (now very widely used) to detect thresholds. Simply put, the idea is to assume that background pixels (unwanted), and foreground pixels (your signal) will follow a bimodal distribution, i.e. that all the background pixels will be a well defined group on a histogram, which will be different from another well defined group that will be brighter, and is the signal that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"the objective masking threshold for this dataset is:\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the global threshold produces masks with different qualtities at the edges and the center of the image because of the uneven illumination throughout the sample. Observe the histogram of pixel intensities to see why this might be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(data.flatten(), hist_kws={'log': True}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might the unneveness of the illumination compromise the algorithm? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank filters: local image manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steal Noah's intro module on rank filters to explain how to flatten the field (or, alternatively subtract local background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#flatten the field to show that it improves Otsu's method--show the new histogram\n",
    "    #Methods: rolling ball, subtract Gaussian blur, large min filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show new masks-- they are improved but still have holes and rogue noisy pixels\n",
    "#removing shot noise: median filtering (shown below)\n",
    "#morphological processing (From Morphological Image Processing module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Shot Noise from your Image -- Median Fitering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better at object detection, we can leverage various properties of the pixels. With time, you will be able to leverage pretty much any property you can articulate, but for now, let's use the idea that the pixels that are hanging out in the wrong places are surrounded by other pixels that are properly classified. Let's make them listen to their neighbours. There are many ways to do this. One useful method to know is called Median filtering. It goes pixel by pixel, and replaces each pixel with the median of its surroundings. Let's load our image slice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import median_filter\n",
    "plt.imshow(original_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tech tip: These images were taken with a confocal microscope, which uses a PMT (photomultiplier tube) with high sensitivity. However, because this detector operates in a low-photon regime, shot noise (Poisson distributed) can add substantial deviation of pixel values from the local fluorescence intensities they represent. Shot noise is commonly removed with the median filter, although other rank filters exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "\n",
    "@interactive\n",
    "def apply_filter(size=(1, 21)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    \n",
    "    # Here we implement the median filtering\n",
    "    filtered = median_filter(original_slice, size=size)\n",
    "                             \n",
    "    ax[0].imshow(original_slice)\n",
    "    ax[1].imshow(filtered)\n",
    "    dif_img = filtered.astype('int') - original_slice.astype('int')\n",
    "    \n",
    "    extreme = 10000\n",
    "    im = ax[2].imshow(dif_img, vmin=-extreme, vmax=extreme, cmap='coolwarm')\n",
    "    \n",
    "    print(\"total difference in image =\" + str(np.mean(dif_img)) + \" arbitrary units\")\n",
    "    print(\"percent change =\" + str(np.mean(dif_img)/100) + \"%\") \n",
    "apply_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that the size of the filter determines the value of the median value of the pixels in the output. That means, the larger the filter size, the more neighbours the filter will look at, before deciding what the new pixel value should be. A good rule of thumb when determining an appropriate filter size is that it should be the smallest filter that sufficiently flattens the visible noise in the background. Many of these operations do not have well-accepted statistical tests for determing the appropriate parameters, so care needs to be taken to record and reproduce processing steps with the same parameters. \n",
    "\n",
    "Let's choose a filter size of 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_slice = median_filter(original_slice, size=3)\n",
    "filtered_image = median_filter(whole_image, size=3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(filtered_image)\n",
    "ax[1].imshow(filtered_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the filtering affects our mask, and compare to the mask we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_filtered_slice = threshold_image(filtered_slice, filters.threshold_otsu(filtered_slice))\n",
    "masked_filtered_image = threshold_image(filtered_image, filters.threshold_otsu(filtered_image))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_image)\n",
    "ax[1].imshow(masked_slice)\n",
    "ax[2].imshow(masked_filtered_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but still not perfect! What do you think would happen if we tried to apply the mask before the filter? (this could be an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_masked_slice = median_filter(masked_slice, size=3)\n",
    "filtered_masked_image = median_filter(masked_whole_image, size=3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_slice)\n",
    "ax[1].imshow(filtered_masked_slice)\n",
    "ax[2].imshow(masked_filtered_slice - filtered_masked_slice, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does doing this not make sense? (this leads to discussion of morphological operations...)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
