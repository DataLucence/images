{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Pre-processing Part 1 - Global Thresholds\n",
    "\n",
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "In this module, you will\n",
    "- Review how to load digital images and associated metadata\n",
    "- Understand what it means to find a threshold for an image\n",
    "- Use a threshold to make a mask, i.e. separate the background and foreground of an image\n",
    "- Learn how to use Otsu's method to find threshold values\n",
    "- Understand the mechanics of Otsu's method, and learn its limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, a note about Jupyter notebooks for preprocessing pipelines:  \n",
    "\n",
    "They are great for the type of quick data visualization that you might want when developing an analysis pipeline. However, it's hard to build on notebooks or use functionalities in them between projects. For this reason, you may want to consider moving your most useful functions into scripts and working that way when looping through many types of data.  \n",
    "\n",
    "That said, few things as transparently demonstrate an analysis workflow, and they make wonderful supplements to the Materials sections of papers.  \n",
    "See http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261   \n",
    "https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks   \n",
    "notable example: http://nbviewer.jupyter.org/github/WagnerLabPapers/Waskom_JNeurosci_2014/blob/master/Behavioral_and_Decoding_Analyses.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today's project\n",
    "\n",
    "We will work with fluorescence microscopy data to characterize how vinculin contributes to cell spreading and focal adhesion formation. \n",
    "\n",
    "The signals that we will be looking at are phalloidin (F-actin), paxillin-EGFP (focal adhesion protein), and Heochst (nuclei). \n",
    "\n",
    "Hypothesis:\n",
    " - Preprocessing Part 1: Vinculin promotes cell spreading. The vinculin-null cells will have a spreading defect.\n",
    " - Preprocessing Part 2: Vinculin promotes focal adhesion formation. Vinculin-null cells will have fewer focal adhesions, smaller focal adhesions, or less focal total focal adhesion area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First some boilerplate code to make it easier to access useful libraries, \n",
    "#     and to make it easier to visualize data in the notebook...\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage\n",
    "\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set a variable to the folder where all of your test data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = \"../data/20170601-ROCK-vinc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Load the WT and vincKO images into memory and report the dimensions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "wt_data = imread(data_path + \"20170601-WT-DMSO-1.tif\")\n",
    "vinc_data = imread(data_path + \"20170601-vincKO-DMSO-1.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wt_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the metadata:   \n",
    "Here I have saved the metadata in a file format called json. Json files are easily loaded into python as the dictionary data type. Dictionaries in python are indexed with keys, which are strings instead of numerical indices (such as used in lists). To understand this concept, load the below json file and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(data_path + \"20170601-vincKO-DMSO-1.json\", mode='r') as metadata_wt:\n",
    "    meta_wt = json.load(metadata_wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the information stored in this dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in meta_wt:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_wt[\"channels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to organize your data into a dict instead of a numerical array when one of the dimensions of the array corresponds to something that is non-numerical in nature. Here, the channel dimension is stored as another dimension in the numerical array that is wt_data. To get the image corresponding to one of the channels, you would have to remember which of the channel slices corresponds to the channel you would like to see. Below we'll organize the data into a dict so that the channels can be indexed by an intuitive string and not a numerical index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wt = {}\n",
    "vinc = {}\n",
    "\n",
    "for idx, channel in enumerate(meta_wt['channels']):\n",
    "    wt[channel] = wt_data[:,:,idx]\n",
    "    vinc[channel] = vinc_data[:,:,idx]\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Set the wild type actin slice to the variable \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(wt[\"actin\"])\n",
    "ax[1].imshow(wt['nucleus'])\n",
    "ax[2].imshow(wt[\"pax\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(vinc[\"actin\"])\n",
    "ax[1].imshow(vinc['nucleus'])\n",
    "ax[2].imshow(vinc[\"pax\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Use imshow to zoom in on a small section of the pax images to examine the small structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#answer to exercise\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(vinc[\"pax\"][700:900,400:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing: a motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: write a function that has the following attributes:   \n",
    "- Input: numerical threshold and input image\n",
    "- Output: visualization of the the images binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#answer\n",
    "def mask_im(im, threshold):\n",
    "    mask = np.zeros(im.shape)\n",
    "    mask[im >=threshold] = 1\n",
    "    plt.imshow(mask, vmin = 0, vmax = 1)\n",
    "    return(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vinc['actin'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = vinc[\"actin\"]\n",
    "data2 = wt[\"actin\"]\n",
    "\n",
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_masks(thresh=(0, data1.max() * 0.3, 40)):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(64, 16))\n",
    "    mask1 = np.zeros(data1.shape)\n",
    "    mask2 = np.zeros(data2.shape)\n",
    "    \n",
    "    mask1[data1 >=thresh] = 1\n",
    "    mask2[data2 >=thresh] = 1\n",
    "    \n",
    "    ax[0].imshow(mask1, vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask2, vmin=0, vmax=1)\n",
    "show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Determine a global threshold for the nucleus channel of both images. Discuss what is preventing this from working robustly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will define the ROIs in this set of images. You may have noticed some qualities of the above images that make them hard to reliably threshold into masks relecting the relevant cell organelles.\n",
    "\n",
    "Addressed in Preprocessing part 1:\n",
    "1. There appears to be some variation in the background and intensity between actin datasets. Perhaps there was some variability in the focus when the image was taken, someone opened the microscope room door during imaging of one of the datasets, pipetting error when staining, or that some of the cells really do have more actin.   \n",
    "    - automated thresholding methods\n",
    "    \n",
    "Addressed preprocessing part 2:\n",
    "2. Noise corrupting the images\n",
    "    - Introduction to Rank Filters: median filter\n",
    "2. Uneven illumination in the nucleus channel makes finding a single threshold across a single image challenging. \n",
    "    - Rolling ball background subtraction\n",
    "3. Uneven paxillin expression, low EGFP signal, and cytoplasmic signal complicate focal adhesion thresholding\n",
    "    - thresholding within defined ROIs\n",
    "    \n",
    "Addressed in Morphological Operations:\n",
    "4. Small blobs appear in nuclear mask, making it hard to count nuclei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the cell bodies depends on the threshold chosen. It may be challenging to choose a single threshold for making masks across datasets, especially if there are slight differences in focus or background. This emphasizes the need for more reproducible thresholding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = wt['actin'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated detection of foreground using Otsu's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobuyuki Otsu proposed a method (now very widely used) to detect thresholds. Simply put, the idea is to assume that background pixels (unwanted), and foreground pixels (your signal) will follow a bimodal distribution, i.e. that all the background pixels will be a well defined group on a histogram, which will be different from another well defined group that will be brighter, and is the signal that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"The objective masking threshold for this dataset is:\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = mask_im(data,thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the global threshold produces masks with different qualities at the edges and the center of the image because of the uneven illumination throughout the sample. Observe the histogram of pixel intensities to see why this might be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(data.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r', label='Otsu threshold')\n",
    "plt.legend()\n",
    "plt.ylim(0,30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both manual threshold determination and Otsu's threshold determination fail to produce high-quality masks in this dataset. Noise, uneven illumination, and background, which are all common in fluorescent microscopy datasets in biology, can be corrected using a set of *rank filters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: View the histogram of pixel values for the nucleus dataset. Does Otsu's method make sense? Perform Otsu's thresholding on the nucleus dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nuc_thresh = filters.threshold_otsu(wt['nucleus'])\n",
    "print(\"The calculated masking threshold for the nucleus is:\", nuc_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(wt['nucleus'].flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(nuc_thresh, ls='--', lw=2, c='r', label='Otsu threshold')\n",
    "plt.legend()\n",
    "plt.ylim(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nuc_mask2 = mask_im(wt[\"nucleus\"], nuc_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** we will save the application of Otsu's thresholding method to the image by imshow the mask in the next exercise.\n",
    "\n",
    "Now back to our actin data. Spatial filtering (to be covered next) can help separate the intensity histogram into distinct peaks, which may improve the performance of Otsu's method. Below is a dataset which was heavily filtered to remove the saturated pixels, noise, and reduce the holes in the cytoplasm. Does Otsu's method work now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "wt_im = imread(\"../fig/20170601-WT-DMSO-1-actin-blur.tif\")\n",
    "vinc_im = imread(\"../fig/20170601-vincKO-DMSO-1-actin-blur.tif\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "wt_act_mask = mask_im(wt['actin'], filters.threshold_otsu(wt_im))\n",
    "ax[0].imshow(mask, vmin = 0, vmax = 1)\n",
    "ax[1].imshow(wt_im)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "mask = mask_im(vinc['actin'], filters.threshold_otsu(vinc_im) )\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(vinc_im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "wt_thresh= filters.threshold_otsu(wt_im)\n",
    "\n",
    "sns.distplot(wt_im.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(wt_thresh, ls='--', lw=2, c='r')\n",
    "plt.gca().set_ylim([0, 300000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This threshold seems like it's dividing a cluster instead of separating two clusters, even though empirically the histogram looks like two populations. While Otsu's is the most recognized of the thresholding algorithms, it's ok if after all reasonable processing steps it still fails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Determine what is incorrect about the application of Otsu's method below (there are two independent errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = wt['nucleus']\n",
    "\n",
    "from skimage import filters\n",
    "nuc_thresh = filters.threshold_li(data) # Error 1: threshold method name is wrong!\n",
    "print(\"the Otsu masking threshold for this dataset is:\", nuc_thresh)\n",
    "\n",
    "nuc_mask = np.zeros(data.shape)\n",
    "nuc_mask[data <= nuc_thresh] = 1 # Error 2: binary assignment should be 0\n",
    "\n",
    "plt.imshow(nuc_mask, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise** Otsu's method performs sub-optimally in this case because of the distribution of background and foreground values. \n",
    "Find the documentation for the scipy filter options and determine if another thresholding algorithm would be more appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "nuc_mask = mask_im(wt[\"nucleus\"], filters.threshold_li(data))\n",
    "plt.imshow(label(nuc_mask))\n",
    "print(label(nuc_mask).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wt_masks = {}\n",
    "vinc_masks = {}\n",
    "\n",
    "for ch in wt:\n",
    "    wt_masks[ch] = mask_im(wt[ch], filters.threshold_otsu(wt[ch]))\n",
    "    vinc_masks[ch] = mask_im(vinc[ch], filters.threshold_otsu(vinc[ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_spread_area_wt = np.sum(wt_masks[\"actin\"])\n",
    "total_spread_area_vinc = np.sum(vinc_masks[\"actin\"])\n",
    "\n",
    "num_cells_wt = np.max(label(wt_masks[\"nucleus\"]))\n",
    "num_cells_vinc = np.max(label(vinc_masks[\"nucleus\"]))\n",
    "\n",
    "print(\"spread area per WT cell is\" , total_spread_area_wt/num_cells_wt, \"pixels\")\n",
    "print(\"for\" , num_cells_wt, \"cells\")\n",
    "print( )\n",
    "print(\"spread area per vincKO cell is\" , total_spread_area_vinc/num_cells_vinc, \"pixels\")\n",
    "print(\"for\" , num_cells_vinc, \"cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
