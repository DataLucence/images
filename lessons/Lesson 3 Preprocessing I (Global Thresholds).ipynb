{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Pre-processing Part 1 - Global Thresholds\n",
    "\n",
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "In this module, you will\n",
    "- Review how to load digital images and associated metadata\n",
    "- Understand what it means to find a threshold for an image\n",
    "- Use a threshold to make a mask, i.e. separate the background and foreground of an image\n",
    "- Learn how to use Otsu's method to find threshold values\n",
    "- Understand the mechanics of Otsu's method, and learn its limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with data from an experiment to determine whether treatment with a drug causes a shift in the localization of a protein.\n",
    "\n",
    "Hypothesis: Treatment with drug A will cause a decrease in the total amount of protein Y. You have saved the control dataset as \"DMSO.tif\" and the drugged cell dataset as \"drugA.tif\". \n",
    "\n",
    "First some boilerplate code to make it easier to access useful libraries, and to make it easier to visualize data in the notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark', rc={'image.cmap':'inferno'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import an image file and associated metadata as we learned in the last lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "data_drug = imread(\"../data/confocal_drug_panel/drugA.tif\")\n",
    "data_nodrug = imread(\"../data/confocal_drug_panel/DMSO.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/confocal_drug_panel/DMSO_metadata.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, value in meta_nodrug.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drug_slice = {}\n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    drug_slice[channel] = data_drug[3,:,:,idx]\n",
    "    nodrug_slice[channel] = data_nodrug[3,:,:,idx] #add in the indexing when read in full dataset\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(nodrug_slice[\"actin\"])\n",
    "ax[1].imshow(nodrug_slice['nucleus'])\n",
    "ax[2].imshow(nodrug_slice[\"your_fav_protein\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(drug_slice[\"actin\"])\n",
    "ax[1].imshow(drug_slice['nucleus'])\n",
    "ax[2].imshow(drug_slice[\"your_fav_protein\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Use the metadata, the \"shape\" command, and/or visualization of the slice to determine what \"VARIABLE\" in the following cell denotes. Choose an appropriate value of VARIABLE for this dataset. Then run the cell to organize the nucleus data into a form that's easier to index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use VARIABLE = 4 is recommended; VARIABLE = time or z-section?\n",
    "VARIABLE = 1 # change me! \n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    nodrug_slice[channel] = data_nodrug[VARIABLE,:,:,idx]\n",
    "nucleus_data = nodrug_slice['nucleus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nodrug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View few slices to determine VARIABLE in the previous cell\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(data_nodrug[0, :, :, 1])\n",
    "ax[1].imshow(data_nodrug[4, :, :, 1])\n",
    "ax[2].imshow(data_nodrug[8, :, :, 1])\n",
    "\n",
    "ax[0].set_title(\"VARIABLE = 0\")\n",
    "ax[1].set_title(\"VARIABLE = 4\")\n",
    "ax[2].set_title(\"VARIABLE = 8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the crop parameters to crop out a nucleus (1) in the middle of the image and (2) one on the edge of the image for visualization in the rest of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters to adjust\n",
    "# use minX1 = 450, minY1 = 250, minX2 = 0, minY2 = 250 is recommended\n",
    "nuc_minX1 = 1 # crop edges for a cell in the center of field of view; change me!\n",
    "nuc_minY1 = 1 # change me!\n",
    "nuc_minX2 = 1 # crop edges for cell at the edge of the field of view; change me!\n",
    "nuc_minY2 = 1 # change me!\n",
    "nuc_crop_size = 200 #pix\n",
    "nuc_image_view_thresh = 0.7 #set for the entire notebook so can compare outputs more easily\n",
    "\n",
    "# run\n",
    "nuc_maxX1 = nuc_minX1 + nuc_crop_size\n",
    "nuc_maxY1 = nuc_minY1 + nuc_crop_size\n",
    "nuc_maxX2 = nuc_minX2 + nuc_crop_size\n",
    "nuc_maxY2 = nuc_minY2 + nuc_crop_size\n",
    "\n",
    "nuc_c1 = nucleus_data[nuc_minY1 : nuc_maxY1, nuc_minX1 : nuc_maxX1] #crop of a nucleus in the center of the image\n",
    "nuc_c2 = nucleus_data[nuc_minY2 : nuc_maxY2, nuc_minX2 : nuc_maxX2] #crop of the nucleus at the edge of the image\n",
    "\n",
    "nuc_top = nucleus_data.max() * nuc_image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(nucleus_data, vmin=0, vmax=nuc_top, interpolation = 'nearest')\n",
    "ax[1].imshow(nuc_c1, vmin=0, vmax=nuc_top, interpolation = 'nearest')\n",
    "ax[2].imshow(nuc_c2, vmin=0, vmax=nuc_top, interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing: a motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have images of fixed cells in three channels -- cell bodies labeled with an actin stain, nuclei labeled with DAPI, and a third protein \"your_fav_protein\" that responds to drug treatment. Just by looking at the images it seems like the protein is shifting from the nuclei to the cell body once the drug is applied (always visualize your intermediates!), but it is unclear if the drug treatment changes the total amount of protein per cell as well.\n",
    "\n",
    "To address these questions, you will need to do the following --\n",
    "\n",
    "1. Make a mask of the actin channel to identify pixels within the cell bodies\n",
    "2. Make a mask of the nuclear channel to identify pixels within the nucleus\n",
    "3. Determine the signal coming from *your favorite protein* within these regions of interest. \n",
    "\n",
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "Tomorrow, we will cover how to design your image processing pipeline to deal with some trickier problems, such as quantifying fluorescence in the ROIs determined here. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making masks to localize cell bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodrug_slice['actin'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = nodrug_slice['actin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find an appropriate threshold that defines the cell bodies accurately across the image using the sliding bar. First, view the image more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters to adjust\n",
    "minX1 = 450 #crop edges for a cell in the center of field of view\n",
    "minY1 = 250\n",
    "minX2 = 0 #crop edges for cell at the edge of the field of view\n",
    "minY2 = 250\n",
    "crop_size = 200 #pix\n",
    "image_view_thresh = 0.7\n",
    "\n",
    "#run\n",
    "maxX1 = minX1 + crop_size\n",
    "maxY1 = minY1 + crop_size\n",
    "maxX2 = minX2 + crop_size\n",
    "maxY2 = minY2 + crop_size\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], vmin=0, vmax=top)\n",
    "ax[0].imshow(data, vmin=0, vmax=top)\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], vmin=0, vmax=top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which threshold gives the best mask across the image using the sliding bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_masks(thresh=(0, data.max() * 0.3, 40)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "    mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "    mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "    mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "    ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "    ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Try to determine a threshold for the DAPI nuclei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_nuc_masks(nuc_thresh=(0, data.max() * 0.3, 40)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    nuc_mask = np.zeros(nucleus_data.shape)\n",
    "    nuc_mask[nucleus_data >= nuc_thresh] = 1\n",
    "    nuc_mask_zoom_center = nuc_mask[nuc_minY1 : nuc_maxY1 , nuc_minX1 : nuc_maxX1]\n",
    "    nuc_mask_zoom_edge = nuc_mask[nuc_minY2 : nuc_maxY2 , nuc_minX2 : nuc_maxX2]\n",
    "    ax[0].imshow(nuc_mask, vmin=0, vmax=1)\n",
    "    ax[1].imshow(nuc_mask_zoom_center, vmin=0, vmax=1)\n",
    "    ax[2].imshow(nuc_mask_zoom_edge, vmin=0, vmax=1)\n",
    "show_nuc_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated detection of foreground using Otsu's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobuyuki Otsu proposed a method (now very widely used) to detect thresholds. Simply put, the idea is to assume that background pixels (unwanted), and foreground pixels (your signal) will follow a bimodal distribution, i.e. that all the background pixels will be a well defined group on a histogram, which will be different from another well defined group that will be brighter, and is the signal that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"The objective masking threshold for this dataset is:\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the global threshold produces masks with different qualities at the edges and the center of the image because of the uneven illumination throughout the sample. Observe the histogram of pixel intensities to see why this might be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(data.flatten(), hist_kws={'log': True}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r', label='Otsu threshold')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both manual threshold determination and Otsu's threshold determination fail to produce high-quality masks in this dataset. Noise, uneven illumination, and background, which are all common in fluorescent microscopy datasets in biology, can be corrected using a set of *rank filters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** View the histogram of pixel values for the \"nucleus\" dataset. Does Otsu's method make sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nuc_thresh = filters.threshold_otsu(nucleus_data)\n",
    "print(\"The objective masking threshold for the nucleus is:\", nuc_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(nucleus_data.flatten(), hist_kws={'log': True}, kde=False)\n",
    "plt.axvline(nuc_thresh, ls='--', lw=2, c='r', label='Otsu threshold')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** we will save the application of Otsu's thresholding method to the image by imshow the mask in the next exercise.\n",
    "\n",
    "Now back to our actin data, let's check out whether the Otsu's threshold makes sense for a cleaner image with a pre-determined mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "clean_mask = imread(\"../fig/processed_sample_mask.tif\")\n",
    "clean_im = imread(\"../fig/processed_sample_data.tif\")\n",
    "\n",
    "clean_mask = scipy.ndimage.zoom(clean_mask, mask.shape[0]/clean_mask.shape[0], order=0)\n",
    "clean_im = scipy.ndimage.zoom(clean_im, mask.shape[0]/clean_im.shape[0], order=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "cmask_zoom_center = clean_mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "cmask_zoom_edge = clean_mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(clean_mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(cmask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(cmask_zoom_edge, vmin=0, vmax=1)\n",
    "\n",
    "top = clean_im.max() * image_view_thresh\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "cim_zoom_center = clean_im[minY1 : maxY1 , minX1 : maxX1]\n",
    "cim_zoom_edge = clean_im[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(clean_im, vmin=0, vmax=top)\n",
    "ax[1].imshow(cim_zoom_center, vmin=0, vmax=top)\n",
    "ax[2].imshow(cim_zoom_edge, vmin=0, vmax=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "threshC = filters.threshold_otsu(clean_im)\n",
    "\n",
    "sns.distplot(clean_im.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(threshC, ls='--', lw=2, c='r')\n",
    "plt.gca().set_ylim([0, 300000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This threshold seems like it's dividing a cluster instead of separating two clusters, even though empirically the results look very good. Some algorithms become staples of images processing not because the underlying model they reflect is correct, but because they're extremely robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Determine what is incorrect about the application of Otsu's method to the nucleus data below (there are two independent errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "nuc_thresh = filters.threshold_li(nucleus_data) # Error 1: threshold method name is wrong!\n",
    "print(\"the Otsu masking threshold for this dataset is:\", nuc_thresh)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "nuc_mask = np.zeros(nucleus_data.shape)\n",
    "nuc_mask[nucleus_data <= nuc_thresh] = 1 # Error 2: binary assignment should be 0\n",
    "\n",
    "nuc_mask_zoom_center = nuc_mask[nuc_minY1 : nuc_maxY1 , nuc_minX1 : nuc_maxX1]\n",
    "nuc_mask_zoom_edge = nuc_mask[nuc_minY2 : nuc_maxY2 , nuc_minX2 : nuc_maxX2]\n",
    "\n",
    "ax[0].imshow(nuc_mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(nuc_mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(nuc_mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: Rank filters for locally-informed image manipulations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
