{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Pre-processing Part 2 - Rank Filters\n",
    "\n",
    "Here we continue from Pre-processing Part 1, and introduce the following concepts\n",
    "- The limits of Otsu's method to find global thresholds\n",
    "- The difference between global and local processing methods\n",
    "- A few useful local pre-processing operations\n",
    "    - Using the median filter to remove noise\n",
    "    - Using rolling ball background subtraction\n",
    "- The effect of varying the structuring element on rank filters\n",
    "- How to obtain useful global metrics from processed images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's reestablish the environment we set up in the previous lesson's notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'})\n",
    "import matplotlib.axes as ax\n",
    "\n",
    "data_nodrug = imread(\"../data/confocal_drug_panel/DMSO.tif\")\n",
    "\n",
    "import json\n",
    "with open('../data/confocal_drug_panel/DMSO_metadata.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)\n",
    "\n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    nodrug_slice[channel] = data_nodrug[2,:,:,idx]    \n",
    "data = nodrug_slice['actin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the raw data and masks generate from global Otsu's threshold in Pre-processing Part 1 - Global Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters to adjust\n",
    "minX1 = 450 #crop edges for a cell in the center of field of view\n",
    "minY1 = 250\n",
    "minX2 = 0 #crop edges for cell at the edge of the field of view\n",
    "minY2 = 250\n",
    "crop_size = 200 #pix\n",
    "image_view_thresh = 0.7 #set for the entire notebook so can compare outputs more easily\n",
    "\n",
    "#run\n",
    "maxX1 = minX1 + crop_size\n",
    "maxY1 = minY1 + crop_size\n",
    "maxX2 = minX2 + crop_size\n",
    "maxY2 = minY2 + crop_size\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], vmin=0, vmax=top, interpolation = 'nearest')\n",
    "ax[0].imshow(data, vmin=0, vmax=top, interpolation = 'nearest')\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], vmin=0, vmax=top, interpolation = 'nearest')\n",
    "\n",
    "from skimage import filters\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"the Otsu masking threshold for this dataset is:\", thresh)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "mask = np.zeros(data.shape)\n",
    "mask[data >=thresh] = 1\n",
    "mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "\n",
    "crop_edge = data[minY2 : maxY2, minX2: maxX2]\n",
    "crop_mid = data[minY1 : maxY1 , minX1 : maxX1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to rank filters: denoising with the median filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the problems with the dataset that produce low-quality ROIs:\n",
    "1) Noise\n",
    "2) Uneven illumination\n",
    "\n",
    "Rank filters are a subset of common image processing tools that modify images pixel-by-pixel by including information about the surrounding pixels. They do the heavy lifting in many algorithms for denoising (here the median filter), flattening illumination or background, and morphological manipulations. \n",
    "\n",
    "The skimage piece on rank filters (http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_rank_filters.html#sphx-glr-auto-examples-xx-applications-plot-rank-filters-py) explains different types of filters and has sample code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters.rank import minimum as min_filter\n",
    "from skimage.morphology import disk\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these filters work pixel-by-pixel, let's first zoom in on a small portion of our original dataset. Note that we specify 'nearest' interpolation so that imshow does not blur our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zoom = crop_edge[75:95 , 50:70]\n",
    "plt.imshow(zoom, interpolation='nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate an abberantly dark pixel at a known location (to protect your lesson from variation in input datasets) and an abberantly bright pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dark_pix_x = 10\n",
    "dark_pix_y = 5\n",
    "bright_pix_x = 15\n",
    "bright_pix_y = 5\n",
    "\n",
    "zoom_noised = zoom.copy()\n",
    "zoom_noised[bright_pix_y, bright_pix_x] = zoom.max()*2\n",
    "zoom_noised[dark_pix_y, dark_pix_x] = 0\n",
    "plt.imshow(zoom_noised, interpolation='nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These abberant pixel values do not accurately reflect the local concentration of your fluorescent protein, but instead a faulty detector on your camera (for ccds or scmos) or noise. Rank filters use the information from the pixels in the neighborhood of this pixel to reassign a value in the \"filtered\" image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dark pixel in the image and the pixels immediately surrounding it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(zoom_noised, interpolation='nearest')\n",
    "nhood = 3 #works best with an odd number, but an even number could demonstrate the problem with some even-numbered structuring element sizes\n",
    "\n",
    "#plt.gca().add_patch(plt.Rectangle((bright_pix_x-nhood/2, bright_pix_y-nhood/2), nhood, nhood, fill=None, color='y', lw=2))\n",
    "plt.gca().add_patch(plt.Rectangle((dark_pix_x-nhood/2, dark_pix_y-nhood/2), nhood, nhood, fill=None, color='y', lw=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"There is a lot of information about what that pixel value could be based on its neighbors. \",\n",
    "      \"Their values are:\")\n",
    "NHOOD = zoom_noised[int(dark_pix_y - (nhood-1)/2 ) : int(dark_pix_y + (nhood-1)/2) +1 , int(dark_pix_x - (nhood-1)/2) : int(dark_pix_x + (nhood-1)/2 )+1]\n",
    "print( NHOOD)\n",
    "\n",
    "print(\"ranked, the values are\" , sorted(NHOOD.flatten()) )\n",
    "print(\"with a median value of \", np.median(NHOOD))\n",
    "\n",
    "print(\"If this were one step in a median filter, the median value in the neighborhood would become\", np.median(NHOOD), \"in the new, filtered image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, performing these manipulations on choice pixels is not a reproducible approach, and fortunately there are good built-in 2D median filters that will process each pixel in the image by considering its neighbors. A median filter applied to each pixel in the image above results in noise reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a median filter with the parameters in the example above using the skimage rank filters and skimage morphology libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters.rank import median as median_filter\n",
    "from skimage.morphology import square\n",
    "\n",
    "plt.imshow(median_filter(zoom_noised, square(nhood) ) , interpolation='nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filter was applied to the entire image (pixel by pixel) and resulted in loss of the abberant bright and dark pixels. What else do you notice about the image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring elements: determining the neighborhood for rank filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the neighborhood considered for determining the output for each pixel was the set of pixels immediately adjacent to our pixel of interest in a square (the pixels boxed in the example above). The shape and size of the neighborhood used in the algorithm is called the structuring element.\n",
    "\n",
    "You have total freedom to choose any structuring element you want, but generally simple symmetric shapes are used because their effects are intuitive. In fact, we can let `scikit-image` generate reasonable structuring elements for us! This is a good idea to maximize repeatability.\n",
    "\n",
    "See: http://scikit-image.org/docs/dev/api/skimage.morphology.html for some options.\n",
    "\n",
    "\"Disk,\" which approximates a circle around the filtered pixel, is a common choice for structuring element. The skimage.morphology library structuring elements can be viewed directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Filters Example 1: Median Filter\n",
    "\n",
    "#### Influence of structuring element size on image output\n",
    "\n",
    "View the size and shape of the \"disk\" structuring element included in the skimage morpholoogy package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import disk\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    N = 5\n",
    "    fig, axes = plt.subplots(1, N, figsize=(16, 3))\n",
    "    for n, ax in enumerate(axes):\n",
    "        np1 = n + 1\n",
    "        ax.imshow(np.pad(disk(np1), N-n, 'constant'), interpolation='nearest')\n",
    "        c = plt.Circle((np1 + N - n, np1 + N - n), radius=np1, fill=False, lw=4, color='b')\n",
    "        ax.add_artist(c)\n",
    "        ax.set_xlim(0, 2 * N + 2)\n",
    "        ax.set_ylim(0, 2 * N + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the effect of changing the size of the structuring element used to median filter the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extreme = 1000\n",
    "\n",
    "from skimage.filters.rank import median as median_filter\n",
    "from ipywidgets import interactive\n",
    "\n",
    "im_filter = zoom_noised\n",
    "\n",
    "@interactive\n",
    "def apply_filter(s=(1, 10)):\n",
    "    # Here we implement the median filtering\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    ax[0].imshow(im_filter, interpolation = 'nearest')\n",
    "    ax[0].set_title('original')\n",
    "    filtered = median_filter(im_filter, disk(s))\n",
    "    dif_img = filtered.astype('int') - im_filter.astype('int')\n",
    "    print(\"total difference in image =\" + str(np.mean(dif_img)) + \" arbitrary units\")\n",
    "    print(\"percent change =\" + str(np.mean(dif_img)/100) + \"%\")                     \n",
    "    ax[1].imshow(filtered, interpolation = 'nearest')\n",
    "    ax[1].set_title('filtered with s = {0:d}'.format(s))\n",
    "    ax[2].imshow(dif_img, vmin=-extreme, vmax=extreme, cmap='coolwarm',interpolation = 'nearest')\n",
    "    ax[2].set_title('difference between images')\n",
    "apply_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the filter determines the value of the pixels in the output as well as how much the output is blurred by the filter. That means, the larger the filter size, the more neighbours the filter will include before deciding what the new pixel value should be. A good rule of thumb when determining an appropriate filter size is that it should be the smallest filter that sufficiently flattens the visible noise in the background. Many of these operations do not have well-accepted statistical tests for determing the appropriate parameters, so care needs to be taken to record and reproduce processing steps with the same parameters. \n",
    "\n",
    "Let's choose a filter size of 2x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_size = 2\n",
    "filtered_im = median_filter(data, disk(f_size))\n",
    "filtered_crop_edge = median_filter(crop_edge, disk(f_size))\n",
    "filtered_crop_mid = median_filter(crop_mid, disk(f_size))\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20, 10))\n",
    "ax[0, 0].imshow(data, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[0, 1].imshow(crop_edge, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[0, 2].imshow(crop_mid, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1, 0].imshow(filtered_im, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1, 1].imshow(filtered_crop_edge, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1, 2].imshow(filtered_crop_mid, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "\n",
    "ax[0, 0].set_title('Original')\n",
    "ax[0, 1].set_title('Zoom on edge')\n",
    "ax[0, 2].set_title('Zoom in center')\n",
    "ax[1, 0].set_title('Filtered')\n",
    "ax[1, 1].set_title('Filtered: Zoom on edge')\n",
    "ax[1, 2].set_title('Filetered: Zoom in center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median filter removed much of the noise!\n",
    "\n",
    "Now let's see how the filtering affects our mask, and compare to the mask we made earlier.\n",
    "\n",
    "**Exercise** Match the output image to the operation that produced it (from a single input image)\n",
    "\n",
    "Match the sample figure to the type of operation performed on it (with a disk structuring element):\n",
    "\n",
    "    1) Mean filter, s=10\n",
    "    2) Min filter, s=10\n",
    "    3) Max filter, s=10\n",
    "    4) Mean filter, s=2\n",
    "    5) Min filter, s=2\n",
    "    6) Max filter, s=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image # Access IPython's browser-based image display.\n",
    "Image(\"../fig/raw_for_types_of_filters_exercise.png\") # Quickly display a diagram we saved in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(\"../fig/types_of_filters_exercise.png\") # Quickly display a diagram we saved in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read image\n",
    "img = imread(\"../fig/raw_for_types_of_filters_exercise.png\")\n",
    "\n",
    "# image preprocessing\n",
    "from skimage.filters.rank import mean as mean_filter\n",
    "from skimage.filters.rank import minimum as min_filter\n",
    "from skimage.filters.rank import maximum as max_filter\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10, 5))\n",
    "ax[0, 0].imshow(mean_filter(img, disk(10)), interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[0, 1].imshow(min_filter(img, disk(10)), interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[0, 2].imshow(max_filter(img, disk(10)), interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1, 0].imshow(mean_filter(img, disk(2)), interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1, 1].imshow(min_filter(img, disk(2)), interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1, 2].imshow(max_filter(img, disk(2)), interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "\n",
    "ax[0, 0].set_title('Mean fitler, s = 10')\n",
    "ax[0, 1].set_title('Min fitler, s = 10')\n",
    "ax[0, 2].set_title('Max fitler, s = 10')\n",
    "ax[1, 0].set_title('Mean fitler, s = 2')\n",
    "ax[1, 1].set_title('Min fitler, s = 2')\n",
    "ax[1, 2].set_title('Max fitler, s = 2')\n",
    "\n",
    "ax[0, 0].set_xticklabels('')\n",
    "ax[0, 1].set_xticklabels('')\n",
    "ax[0, 2].set_xticklabels('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our actin image, let's now create a mask using the filtered image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = filters.threshold_otsu(filtered_im)\n",
    "\n",
    "masked_filtered_im = np.zeros(filtered_im.shape)\n",
    "masked_filtered_crop_edge = np.zeros(filtered_crop_edge.shape)\n",
    "masked_filtered_crop_mid = np.zeros(filtered_crop_mid.shape)\n",
    "\n",
    "masked_filtered_im[filtered_im > thresh] = 1\n",
    "masked_filtered_crop_edge[filtered_crop_edge > thresh] = 1\n",
    "masked_filtered_crop_mid[filtered_crop_mid > thresh] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[0].set_title('Before filtering')\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_im, vmin=0, vmax=1)\n",
    "ax[0].set_title('After filtering')\n",
    "ax[2].imshow(masked_filtered_crop_edge, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_filtered_crop_mid, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, denoising creates smoother masks but the resultant global threshold from Otsu's method still does not handle cells in the center of the image as well as cells at the edge of the image. To understand why, see the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(filtered_im.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r', label='Otsu threshold')\n",
    "plt.gca().set_ylim([0, 200000])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Rank Filters Example 2: Rolling Ball Background Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem in the image comes from non-uniform illumination. Let's now find out the background of the image using a rolling ball or minimum filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "structuring_element = disk(101)\n",
    "background = min_filter(filtered_im, structuring_element)\n",
    "plt.imshow(background, cmap='inferno', vmin = 0, vmax = top*0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's substract this background from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bgs = filtered_im - background\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(bgs, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1].imshow(bgs[minY1:maxY1, minX1:maxX1], interpolation = 'nearest', vmin = 0, vmax = top*0.5)\n",
    "ax[2].imshow(bgs[minY2:maxY2, minX2:maxX2], interpolation = 'nearest', vmin = 0, vmax = top*0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use Otsu's method to find out the global threshold for the background subtracted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = filters.threshold_otsu(bgs)\n",
    "\n",
    "masked_bgs = np.zeros(bgs.shape)\n",
    "masked_bgs_crop_edge = np.zeros(bgs[minY1:maxY1, minX1:maxX1].shape)\n",
    "masked_bgs_crop_mid = np.zeros(bgs[minY2:maxY2, minX2:maxX2].shape)\n",
    "\n",
    "masked_bgs[bgs > thresh] = 1\n",
    "masked_bgs_crop_edge[bgs[minY1:maxY1, minX1:maxX1] > thresh] = 1\n",
    "masked_bgs_crop_mid[bgs[minY2:maxY2, minX2:maxX2] > thresh] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_im, vmin=0, vmax=1)\n",
    "ax[0].set_title('Before background subtraction')\n",
    "ax[2].imshow(masked_filtered_crop_edge, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_filtered_crop_mid, vmin=0, vmax=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_bgs, vmin=0, vmax=1)\n",
    "ax[0].set_title('After background subtraction')\n",
    "ax[1].imshow(masked_bgs_crop_edge, vmin=0, vmax=1)\n",
    "ax[2].imshow(masked_bgs_crop_mid, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see whether Otsu's threshold makes sense for our background subtracted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(bgs.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.gca().set_ylim([0, 40000])\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r', label='Otsu threshold')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that subtraction of background now separates the intensities into two distinct populations but Otsu's fails because of the shape of the distribution (the foreground has a long tail)\n",
    "\n",
    "**Exercise** Apply other thresholding methods\n",
    "\n",
    "Otsu's method performs sub-optimally in this case because of the distribution of background and foreground values. Find the documentation for the scipy filter options and determine if another thresholding algorithm would be more appropriate.\n",
    "\n",
    "Here is the link: http://scikit-image.org/docs/dev/api/skimage.filters.html\n",
    "\n",
    "It would be cool if they found the following function in the documentation: \n",
    "skimage.filters.try_all_threshold(image, figsize=(8, 5), verbose=True)\n",
    "\n",
    "(this is listed right below the other filter options)\n",
    "\n",
    "**CAUTION** thresh_minimum will take forever to run for this particular image, so that it's better not to run try_all_threshold here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh_otsu = filters.threshold_otsu(bgs)\n",
    "thresh_li = filters.threshold_li(bgs)\n",
    "thresh_yen = filters.threshold_yen(bgs)\n",
    "\n",
    "sns.distplot(bgs.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.gca().set_ylim([0, 20000])\n",
    "plt.gca().set_xlim([0, 20000])\n",
    "plt.axvline(thresh_otsu, ls='--', lw=2, c='r', label='otsu')\n",
    "plt.axvline(thresh_li, ls='--', lw=2, c='b', label='li')\n",
    "plt.axvline(thresh_yen, ls='--', lw=2, c='g', label='yen')\n",
    "plt.legend()\n",
    "\n",
    "print('thresh_otsu = ', thresh_otsu)\n",
    "print('thresh_li = ', thresh_li)\n",
    "print('thresh_yen = ', thresh_yen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Yen's method does a good job in separating the background from the foreground. Now let's apply Yen's threshold to create a new mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = filters.threshold_yen(bgs)\n",
    "\n",
    "masked_bgs = np.zeros(bgs.shape)\n",
    "masked_bgs_crop_edge = np.zeros(bgs[minY1:maxY1, minX1:maxX1].shape)\n",
    "masked_bgs_crop_mid = np.zeros(bgs[minY2:maxY2, minX2:maxX2].shape)\n",
    "\n",
    "masked_bgs[bgs > thresh] = 1\n",
    "masked_bgs_crop_edge[bgs[minY1:maxY1, minX1:maxX1] > thresh] = 1\n",
    "masked_bgs_crop_mid[bgs[minY2:maxY2, minX2:maxX2] > thresh] = 1\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[0].imshow(data, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(masked_bgs, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_bgs_crop_edge, vmin=0, vmax=1)\n",
    "ax[2].imshow(masked_bgs_crop_mid, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: Morphological Operations. This follows directly from this lesson in that morphological image processing is an implementation of a rank filter. It expands on the idea of different types of structuring elements (kernals) and how they modify images. Cleaning up the masks above with morphological image processing would be necessary to do analysis on whole cells (probably good to remove the small blobs) so can assign pixels to cells. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
