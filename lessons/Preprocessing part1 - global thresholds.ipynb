{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "Hypothesis: Treatment with drug A will cause a decrease in the total amount of protein Y. You have saved the control dataset as \"DMSO.tif\" and the drugged cell dataset as \"drugA.tif\". \n",
    "\n",
    "First some boilerplate code to make it easier to access useful libraries, and to make it easier to visualize data in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark', rc={'image.cmap':'inferno'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import an image file and associated metadata as we learnt yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "data_drug = imread(\"../data/confocal_drug_panel/drugA.tif\")\n",
    "data_nodrug = imread(\"../data/confocal_drug_panel/DMSO.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../data/confocal_drug_panel/DMSO_metadata.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)\n",
    "\n",
    "drug_slice = {}\n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    drug_slice[channel] = data_drug[3,:,:,idx]\n",
    "    nodrug_slice[channel] = data_nodrug[3,:,:,idx] #add in the indexing when read in full dataset\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(nodrug_slice[\"actin\"])\n",
    "ax[1].imshow(nodrug_slice['nucleus'])\n",
    "ax[2].imshow(nodrug_slice[\"your_fav_protein\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(drug_slice[\"actin\"])\n",
    "ax[1].imshow(drug_slice['nucleus'])\n",
    "ax[2].imshow(drug_slice[\"your_fav_protein\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing: a motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we have images of fixed cells in three channels -- cell bodies labeled with an actin stain, nuclei labeled with DAPI, and a third protein \"your_fav_protein\" that responds to drug treatment. Just by looking at the images it seems like the protein is shifting from the nuclei to the cell body once the drug is applied (always visualize your intermediates!), but it is unclear if the drug treatment changes the total amount of protein per cell as well.\n",
    "\n",
    "To address these questions, you will need to do the following --\n",
    "\n",
    "1. Make a mask of the actin channel to identify pixels within the cell bodies\n",
    "2. Make a mask of the nuclear channel to identify pixels within the nucleus\n",
    "3. Determine the signal coming from *your favorite protein* within these regions of interest. \n",
    "\n",
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "Tomorrow (Day 4), we will cover how to design your image processing pipeline to deal with some trickier problems, such as quantifying fluorescence in the ROIs determined here. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making masks to localize cell bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodrug_slice['actin'].dtype\n",
    "data = nodrug_slice['actin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find an appropriate threshold that defines the cell bodies accurately across the image using the sliding bar.**\n",
    "First, view the image more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters to adjust\n",
    "minX1 = 400 #crop edges for a cell in the center of field of view\n",
    "minY1 = 500\n",
    "minX2 = 650 #crop edges for cell at the edge of the field of view\n",
    "minY2 = 1\n",
    "crop_size = 200 #pix\n",
    "image_view_thresh = 0.1\n",
    "\n",
    "#run\n",
    "maxX1 = minX1 + crop_size\n",
    "maxY1 = minY1 + crop_size\n",
    "maxX2 = minX2 + crop_size\n",
    "maxY2 = minY2 + crop_size\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], vmin=0, vmax=top)\n",
    "ax[0].imshow(data, vmin=0, vmax=top)\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], vmin=0, vmax=top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine using the sliding bar which threshold gives the best mask across the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_masks(thresh=(0, data.max() * 0.1, 20)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "    mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "    mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "    mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "    ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "    ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated detection of foreground using Otsu's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nobuyuki Otsu proposed a method (now very widely used) to detect thresholds. Simply put, the idea is to assume that background pixels (unwanted), and foreground pixels (your signal) will follow a bimodal distribution, i.e. that all the background pixels will be a well defined group on a histogram, which will be different from another well defined group that will be brighter, and is the signal that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"the objective masking threshold for this dataset is:\", thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the global threshold produces masks with different qualtities at the edges and the center of the image because of the uneven illumination throughout the sample. Observe the histogram of pixel intensities to see why this might be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(data.flatten(), hist_kws={'log': True}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both manual threshold determination and Otsu's threshold determination fail to produce high-quality masks in this dataset. Noise, uneven illumination, and background, which are all common in fluorescent microscopy datasets in biology, can be corrected using a set of *rank filters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here add the final corrected image (post illumination flattening, bgs, denoising) as well as intensity histogram and mask as determined by Otsu's to motivate Preprocessing part 2 - rank filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "clean_mask = imread(\"../fig/processed_sample_mask.tif\")\n",
    "clean_im = imread(\"../fig/processed_sample_data.tif\")\n",
    "\n",
    "clean_mask = scipy.ndimage.zoom(clean_mask, mask.shape[0]/clean_mask.shape[0], order=0)\n",
    "clean_im = scipy.ndimage.zoom(clean_im, mask.shape[0]/clean_im.shape[0], order=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "cmask_zoom_center = clean_mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "cmask_zoom_edge = clean_mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(clean_mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(cmask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(cmask_zoom_edge, vmin=0, vmax=1)\n",
    "\n",
    "top = clean_im.max() * 0.2\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "cim_zoom_center = clean_im[minY1 : maxY1 , minX1 : maxX1]\n",
    "cim_zoom_edge = clean_im[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(clean_im, vmin=0, vmax=top)\n",
    "ax[1].imshow(cim_zoom_center, vmin=0, vmax=top)\n",
    "ax[2].imshow(cim_zoom_edge, vmin=0, vmax=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "threshC = filters.threshold_otsu(clean_im)\n",
    "\n",
    "sns.distplot(clean_im.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(threshC, ls='--', lw=2, c='r')\n",
    "plt.gca().set_ylim([0, 500000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This threshold seems like it's dividing a cluster instead of separating two clusters, even though empirically the results look very good. Some algorithms become staples of images processing not because the underlying model they reflect is correct, but because they're extremely robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: Rank filters for locally-informed image manipulations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
