{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this cell if the dataset/variables are not present from running Preprocessing part1 - thresholding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'})\n",
    "import matplotlib.axes as ax\n",
    "\n",
    "data_nodrug = imread(\"../data/confocal_drug_panel/DMSO.tif\")\n",
    "\n",
    "import json\n",
    "with open('../data/confocal_drug_panel/DMSO_metadata.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)\n",
    "\n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    nodrug_slice[channel] = data_nodrug[2,:,:,idx]    #add in the indexing when read in full dataset\n",
    "\n",
    "data = nodrug_slice['actin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the raw data and masks generate from global Otsu's threshold in Preprocessing part 1 - global thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters to adjust\n",
    "minX1 = 350 #crop edges for a cell in the center of field of view\n",
    "minY1 = 450\n",
    "minX2 = 600 #crop edges for cell at the edge of the field of view\n",
    "minY2 = 100\n",
    "crop_size = 200 #pix\n",
    "image_view_thresh = 0.7 #set for the entire notebook so can compare outputs more easily\n",
    "\n",
    "#run\n",
    "maxX1 = minX1 + crop_size\n",
    "maxY1 = minY1 + crop_size\n",
    "maxX2 = minX2 + crop_size\n",
    "maxY2 = minY2 + crop_size\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], vmin=0, vmax=top, interpolation = 'nearest')\n",
    "ax[0].imshow(data, vmin=0, vmax=top, interpolation = 'nearest')\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], vmin=0, vmax=top, interpolation = 'nearest')\n",
    "\n",
    "from skimage import filters\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"the Otsu masking threshold for this dataset is:\", thresh)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "mask = np.zeros(data.shape)\n",
    "mask[data >=thresh] = 1\n",
    "mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "\n",
    "crop_edge = data[minY2 : maxY2, minX2: maxX2]\n",
    "crop_mid = data[minY1 : maxY1 , minX1 : maxX1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to rank filters: denoising with the median filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the problems with the dataset that produce low-quality ROIs:\n",
    "1) Noise\n",
    "2) Uneven illumination\n",
    "\n",
    "Rank filters are a subset of common image processing tools that modify images pixel-by-pixel by including information about the surrounding pixels. They do the heavy lifting in many algorithms for denoising (here the median filter), flattening illumination or background, and morphological manipulations. \n",
    "\n",
    "The skimage piece on rank filters (http://scikit-image.org/docs/dev/auto_examples/applications/plot_rank_filters.html) explains different types of filters and has sample code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.filters.rank import minimum as min_filter\n",
    "from skimage.morphology import disk\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these filters work pixel-by-pixel, let's first zoom in on a small portion of our original dataset. Note that we specify 'nearest' interpolation so that imshow does not blur our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zoom = crop_edge[75:95 , 50:70]\n",
    "plt.imshow(zoom, interpolation='nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate an abberantly dark pixel at a known location (to protect your lesson from variation in input datasets) and an abberantly bright pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dark_pix_x = 10\n",
    "dark_pix_y = 15\n",
    "bright_pix_x = 10\n",
    "bright_pix_y = 5\n",
    "\n",
    "zoom_noised = zoom.copy()\n",
    "zoom_noised[bright_pix_y, bright_pix_x] = zoom.max()*2\n",
    "zoom_noised[dark_pix_y, dark_pix_x] = 0\n",
    "plt.imshow(zoom_noised, interpolation='nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These abberant pixel values do not accurately reflect the local concentration of your fluorescent protein, but instead a faulty detector on your camera (for ccds or scmos) or noise. Rank filters use the information from the pixels in the neighborhood of this pixel to reassign a value in the \"filtered\" image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the dark pixel in the image and the pixels immediately surrounding it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(zoom_noised, interpolation='nearest')\n",
    "nhood = 3 #works best with an odd number, but an even number could demonstrate the problem with some even-numbered structuring element sizes\n",
    "\n",
    "#plt.gca().add_patch(plt.Rectangle((bright_pix_x-nhood/2, bright_pix_y-nhood/2), nhood, nhood, fill=None, color='y', lw=2))\n",
    "\n",
    "plt.gca().add_patch(plt.Rectangle((dark_pix_x-nhood/2, dark_pix_y-nhood/2), nhood, nhood, fill=None, color='y', lw=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"There is a lot of information about what that pixel value could be based on its neighbors. \",\n",
    "      \"Their values are:\")\n",
    "NHOOD = zoom_noised[int(dark_pix_y - (nhood-1)/2 ) : int(dark_pix_y + (nhood-1)/2) +1 , int(dark_pix_x - (nhood-1)/2) : int(dark_pix_x + (nhood-1)/2 )+1]\n",
    "print( NHOOD)\n",
    "\n",
    "print(\"ranked, the values are\" , sorted(NHOOD.flatten()) )\n",
    "print(\"with a median value of \", np.median(NHOOD))\n",
    "\n",
    "print(\"If this were one step in a median filter, the median value in the neighborhood would become\", np.median(NHOOD), \"in the new, filtered image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, performing these manipulations on choice pixels is not a reproducible approach, and fortunately there are good built-in 2D median filters that will process each pixel in the image by considering its neighbors. A median filter applied to each pixel in the image above results in noise reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a median filter with the parameters in the example above using the skimage rank filters and skimage morphology libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.filters.rank import median as median_filter\n",
    "from skimage.morphology import square\n",
    "\n",
    "plt.imshow(median_filter(zoom_noised, square(nhood) ) , interpolation='nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filter was applied to the entire image (pixel by pixel) and resulted in loss of the abberant bright and dark pixels. What else do you notice about the image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring elements: determining the neighborhood for rank filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the neighborhood considered for determining the output for each pixel was the set of pixels immediately adjacent to our pixel of interest in a square (the pixels boxed in the example above). The shape and size of the neighborhood used in the algorithm is called the structuring element.\n",
    "\n",
    "You have total freedom to choose any structuring element you want, but generally simple symmetric shapes are used because their effects are intuitive. In fact, we can let `scikit-image` generate reasonable structuring elements for us! This is a good idea to maximize repeatability.\n",
    "\n",
    "See: http://scikit-image.org/docs/dev/api/skimage.morphology.html for some options.\n",
    "\n",
    "\"Disk,\" which approximates a circle around the filtered pixel, is a common choice for structuring element. The skimage.morphology library structuring elements can be viewed directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Influence of structuring element size on image output: median filter example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the size and shape of the \"disk\" structuring element included in the skimage morpholoogy package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import disk\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    N = 5\n",
    "    fig, axes = plt.subplots(1, N, figsize=(16, 3))\n",
    "    for n, ax in enumerate(axes):\n",
    "        np1 = n + 1\n",
    "        ax.imshow(np.pad(disk(np1), N-n, 'constant'), interpolation='nearest')\n",
    "        c = plt.Circle((np1 + N - n, np1 + N - n), radius=np1, fill=False, lw=4, color='b')\n",
    "        ax.add_artist(c)\n",
    "        ax.set_xlim(0, 2 * N + 2)\n",
    "        ax.set_ylim(0, 2 * N + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the effect of changing the size of the structuring element used to median filter the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extreme = 1000\n",
    "\n",
    "from skimage.filters.rank import median as median_filter\n",
    "from ipywidgets import interactive\n",
    "\n",
    "im_filter = zoom_noised\n",
    "\n",
    "@interactive\n",
    "def apply_filter(s=(1, 10)):\n",
    "    # Here we implement the median filtering\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    ax[0].imshow(im_filter, interpolation = 'nearest')\n",
    "    filtered = median_filter(im_filter, disk(s))\n",
    "    dif_img = filtered.astype('int') - im_filter.astype('int')\n",
    "    print(\"total difference in image =\" + str(np.mean(dif_img)) + \" arbitrary units\")\n",
    "    print(\"percent change =\" + str(np.mean(dif_img)/100) + \"%\")                     \n",
    "    ax[1].imshow(filtered, interpolation = 'nearest')\n",
    "    ax[2].imshow(dif_img, vmin=-extreme, vmax=extreme, cmap='coolwarm',interpolation = 'nearest')\n",
    "apply_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Choose a global threshold for this dataset. Run the cell, and then use the sliding bar to visualize different thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the filter determines the value of the pixels in the output as well as how much the output is blurred by the filter. That means, the larger the filter size, the more neighbours the filter will include before deciding what the new pixel value should be. A good rule of thumb when determining an appropriate filter size is that it should be the smallest filter that sufficiently flattens the visible noise in the background. Many of these operations do not have well-accepted statistical tests for determing the appropriate parameters, so care needs to be taken to record and reproduce processing steps with the same parameters. \n",
    "\n",
    "Let's choose a filter size of 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_size = 2\n",
    "filtered_im = median_filter(data, disk(f_size))\n",
    "filtered_crop_edge = median_filter(crop_edge, disk(f_size))\n",
    "filtered_crop_mid = median_filter(crop_mid, disk(f_size))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(filtered_im, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[2].imshow(filtered_crop_edge, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1].imshow(filtered_crop_mid, interpolation = 'nearest', vmin = 0, vmax = top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median filter removed much of the noise!\n",
    "\n",
    "Now let's see how the filtering affects our mask, and compare to the mask we made earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Match the output image to the operation that produced it (from a single input image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = filters.threshold_otsu(filtered_im)\n",
    "\n",
    "masked_filtered_im = np.zeros(filtered_im.shape)\n",
    "masked_filtered_crop_edge = np.zeros(filtered_crop_edge.shape)\n",
    "masked_filtered_crop_mid = np.zeros(filtered_crop_mid.shape)\n",
    "\n",
    "masked_filtered_im[filtered_im > thresh] = 1\n",
    "masked_filtered_crop_edge[filtered_crop_edge > thresh] = 1\n",
    "masked_filtered_crop_mid[filtered_crop_mid > thresh] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_im, vmin=0, vmax=1)\n",
    "ax[2].imshow(masked_filtered_crop_edge, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_filtered_crop_mid, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, denoising creates smoother masks but the resultant global threshold from Otsu's still does not handle cells at the edges of the image as well as cells in the center of the image. To understand why, see the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(filtered_im.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r')\n",
    "plt.gca().set_ylim([0, 200000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Rank filters example 2: Rolling ball background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "structuring_element = disk(101)\n",
    "background = min_filter(filtered_im, structuring_element)\n",
    "plt.imshow(background, cmap='inferno', vmin = 0, vmax = top*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bgs = filtered_im - background\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(bgs, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[1].imshow(bgs[minY1:maxY1, minX1:maxX1], interpolation = 'nearest', vmin = 0, vmax = top*0.5)\n",
    "ax[2].imshow(bgs[minY2:maxY2, minX2:maxX2], interpolation = 'nearest', vmin = 0, vmax = top*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = filters.threshold_otsu(bgs)\n",
    "\n",
    "masked_bgs = np.zeros(bgs.shape)\n",
    "masked_bgs_crop_edge = np.zeros(bgs[minY1:maxY1, minX1:maxX1].shape)\n",
    "masked_bgs_crop_mid = np.zeros(bgs[minY2:maxY2, minX2:maxX2].shape)\n",
    "\n",
    "masked_bgs[bgs > thresh] = 1\n",
    "masked_bgs_crop_edge[bgs[minY1:maxY1, minX1:maxX1] > thresh] = 1\n",
    "masked_bgs_crop_mid[bgs[minY2:maxY2, minX2:maxX2] > thresh] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_im, vmin=0, vmax=1)\n",
    "ax[2].imshow(masked_filtered_crop_edge, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_filtered_crop_mid, vmin=0, vmax=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_bgs, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_bgs_crop_edge, vmin=0, vmax=1)\n",
    "ax[2].imshow(masked_bgs_crop_mid, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(bgs.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.gca().set_ylim([0, 40000])\n",
    "plt.axvline(thresh, ls='--', lw=2, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that subtraction of background now separates the intensities into two distinct populations but Otsu's fails because of the shape of the distribution (the foreground has a long tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To be determined/discussed by TAs and instructors: \n",
    "\n",
    "Otsu performs sub-optimally, but other thresholding algorithms perform better. How should the choice of algorithm be chosen? \n",
    "\n",
    "**Meta-lesson:**  \n",
    "    1- choosing and changing an algorithm (type of threshold determination in this case)\n",
    "    \n",
    "    2- iteration, and looking at your outputs (how we know we're not using the optimal threshold determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Otsu's method performs sub-optimally in this case because of the distribution of background and foreground values. Find the documentation for the scipy filter options and determine if another thresholding algorithm would be more appropriate. \n",
    "\n",
    "It would be cool if they found the following function in the documentation: \n",
    "skimage.filters.try_all_threshold(image, figsize=(8, 5), verbose=True)\n",
    "\n",
    "\n",
    "(this is listed right below the other filter options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh_otsu = filters.threshold_otsu(bgs)\n",
    "thresh_li = filters.threshold_li(bgs)\n",
    "thresh_yen = filters.threshold_yen(bgs)\n",
    "\n",
    "sns.distplot(bgs.flatten(), hist_kws={'log': False}, kde=False)\n",
    "plt.gca().set_ylim([0, 20000])\n",
    "plt.gca().set_xlim([0, 20000])\n",
    "plt.axvline(thresh_otsu, ls='--', lw=2, c='r')\n",
    "plt.axvline(thresh_li, ls='--', lw=2, c='b')\n",
    "plt.axvline(thresh_yen, ls='--', lw=2, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresh = filters.threshold_yen(bgs)\n",
    "\n",
    "masked_bgs = np.zeros(bgs.shape)\n",
    "masked_bgs_crop_edge = np.zeros(bgs[minY1:maxY1, minX1:maxX1].shape)\n",
    "masked_bgs_crop_mid = np.zeros(bgs[minY2:maxY2, minX2:maxX2].shape)\n",
    "\n",
    "masked_bgs[bgs > thresh] = 1\n",
    "masked_bgs_crop_edge[bgs[minY1:maxY1, minX1:maxX1] > thresh] = 1\n",
    "masked_bgs_crop_mid[bgs[minY2:maxY2, minX2:maxX2] > thresh] = 1\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[0].imshow(data, interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], interpolation = 'nearest', vmin = 0, vmax = top)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(masked_bgs, vmin=0, vmax=1)\n",
    "ax[1].imshow(masked_bgs_crop_edge, vmin=0, vmax=1)\n",
    "ax[2].imshow(masked_bgs_crop_mid, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the Morphological Image Processing module. This follows directly from this lesson in that morphological image processing is an implementation of a rank filter. It expands on the idea of different types of structuring elements (kernals) and how they modify images. Cleaning up the masks above with morphological image processing would be necessary to do analysis on whole cells (probably good to remove the small blobs) so can assign pixels to cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
