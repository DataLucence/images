{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if the dataset/variables are not present from running Preprocessing part1 - thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'})\n",
    "\n",
    "#THE real data to be imported in the class is commented out for now because files are currently too large for github\n",
    "\n",
    "# data_nodrug = imread(\"../data/confocal_drug_panel/DMSO.tif\")\n",
    "data_nodrug = imread(\"../data/confocal_drug_panel/temp_DMSO.tif\")\n",
    "\n",
    "import json\n",
    "with open('../data/confocal_drug_panel/DMSO_metadata.json', mode='r') as f_nodrug:\n",
    "    meta_nodrug = json.load(f_nodrug)\n",
    "\n",
    "nodrug_slice = {}\n",
    "for idx, channel in enumerate(meta_nodrug['channels']):\n",
    "    nodrug_slice[channel] = data_nodrug #[4,:,:,idx]    #add in the indexing when read in full dataset\n",
    "\n",
    "data = nodrug_slice['actin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters to adjust\n",
    "minX1 = 700 #crop edges for a cell in the center of field of view\n",
    "minY1 = 900\n",
    "minX2 = 1200 #crop edges for cell at the edge of the field of view\n",
    "minY2 = 1800\n",
    "crop_size = 200 #pix\n",
    "image_view_thresh = 0.1\n",
    "\n",
    "#run\n",
    "maxX1 = minX1 + crop_size\n",
    "maxY1 = minY1 + crop_size\n",
    "maxX2 = minX2 + crop_size\n",
    "maxY2 = minY2 + crop_size\n",
    "\n",
    "top = data.max() * image_view_thresh\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[1].imshow(data[minY1 : maxY1 , minX1 : maxX1], vmin=0, vmax=top)\n",
    "ax[0].imshow(data, vmin=0, vmax=top)\n",
    "ax[2].imshow(data[minY2 : maxY2, minX2: maxX2], vmin=0, vmax=top)\n",
    "\n",
    "from skimage import filters\n",
    "thresh = filters.threshold_otsu(data)\n",
    "print(\"the Otsu masking threshold for this dataset is:\", thresh)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "mask = np.zeros(nodrug_slice[\"actin\"].shape)\n",
    "mask[nodrug_slice[\"actin\"] >=thresh] = 1\n",
    "mask_zoom_center = mask[minY1 : maxY1 , minX1 : maxX1]\n",
    "mask_zoom_edge = mask[minY2 : maxY2 , minX2 : maxX2]\n",
    "ax[0].imshow(mask, vmin=0, vmax=1)\n",
    "ax[1].imshow(mask_zoom_center, vmin=0, vmax=1)\n",
    "ax[2].imshow(mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#flatten the field to show that it improves Otsu's method--show the new histogram\n",
    "    #Methods: rolling ball, subtract Gaussian blur, large min filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show new masks-- they are improved but still have holes and rogue noisy pixels\n",
    "#removing shot noise: median filtering (shown below)\n",
    "#morphological processing (From Morphological Image Processing module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Shot Noise from your Image -- Median Fitering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better at object detection, we can leverage various properties of the pixels. With time, you will be able to leverage pretty much any property you can articulate, but for now, let's use the idea that the pixels that are hanging out in the wrong places are surrounded by other pixels that are properly classified. Let's make them listen to their neighbours. There are many ways to do this. One useful method to know is called Median filtering. It goes pixel by pixel, and replaces each pixel with the median of its surroundings. Let's load our image slice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import median_filter\n",
    "plt.imshow(original_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tech tip: These images were taken with a confocal microscope, which uses a PMT (photomultiplier tube) with high sensitivity. However, because this detector operates in a low-photon regime, shot noise (Poisson distributed) can add substantial deviation of pixel values from the local fluorescence intensities they represent. Shot noise is commonly removed with the median filter, although other rank filters exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "\n",
    "@interactive\n",
    "def apply_filter(size=(1, 21)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    \n",
    "    # Here we implement the median filtering\n",
    "    filtered = median_filter(original_slice, size=size)\n",
    "                             \n",
    "    ax[0].imshow(original_slice)\n",
    "    ax[1].imshow(filtered)\n",
    "    dif_img = filtered.astype('int') - original_slice.astype('int')\n",
    "    \n",
    "    extreme = 10000\n",
    "    im = ax[2].imshow(dif_img, vmin=-extreme, vmax=extreme, cmap='coolwarm')\n",
    "    \n",
    "    print(\"total difference in image =\" + str(np.mean(dif_img)) + \" arbitrary units\")\n",
    "    print(\"percent change =\" + str(np.mean(dif_img)/100) + \"%\") \n",
    "apply_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the size of the filter determines the value of the median value of the pixels in the output. That means, the larger the filter size, the more neighbours the filter will look at, before deciding what the new pixel value should be. A good rule of thumb when determining an appropriate filter size is that it should be the smallest filter that sufficiently flattens the visible noise in the background. Many of these operations do not have well-accepted statistical tests for determing the appropriate parameters, so care needs to be taken to record and reproduce processing steps with the same parameters. \n",
    "\n",
    "Let's choose a filter size of 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_slice = median_filter(original_slice, size=3)\n",
    "filtered_image = median_filter(whole_image, size=3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(filtered_image)\n",
    "ax[1].imshow(filtered_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the filtering affects our mask, and compare to the mask we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masked_filtered_slice = threshold_image(filtered_slice, filters.threshold_otsu(filtered_slice))\n",
    "masked_filtered_image = threshold_image(filtered_image, filters.threshold_otsu(filtered_image))\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_image)\n",
    "ax[1].imshow(masked_slice)\n",
    "ax[2].imshow(masked_filtered_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but still not perfect! What do you think would happen if we tried to apply the mask before the filter? (this could be an exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_masked_slice = median_filter(masked_slice, size=3)\n",
    "filtered_masked_image = median_filter(masked_whole_image, size=3)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(masked_filtered_slice)\n",
    "ax[1].imshow(filtered_masked_slice)\n",
    "ax[2].imshow(masked_filtered_slice - filtered_masked_slice, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
