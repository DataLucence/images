{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking objects / pipeline design\n",
    "\n",
    "It is important to be able to order the various image processing tools you have learnt in an automated pipeline so you don't have to apply the same N transformations over and over again to your dataset of M images. Today wou will learn how to build your very own image processing pipeline, along with some nifty video processing tools.\n",
    "\n",
    "We will do this in the context of an image processing method known as \"tracking\". You already know how to identify separate objects in your images and measure their properties (position, size, intensity etc.). Now imagine you have a time-series of images (or a video...). Tracking is essentially the ability to identify the same object in your entire time-series consistently. We will also demonstrate how this process can fail, and what to watch out for when you are analyzing your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When do you start developing a pipeline?\n",
    "\n",
    "A typical research plan that a student might present looks like \n",
    "\n",
    "Order supplies --> Build a device --> Collect some data --> Analyze said data --> ~~Profit~~ Publish\n",
    "\n",
    "This process is a pipeline! But it's out of order. Let's find out how with a real-world example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A rat behavior experiment\n",
    "A post-doc wants to do a rat behavior experiment. For the experiment to work, it's critical to know whether or not the rat is moving at any given point in time. Each experiment runs for over an hour, but our post-doc reasons that she can set up a video camera synchronized to the rest of the experimental equipment, record the rat moving around its habitat, and determine when motion happened later, perhaps by doing some image processing. A labmate suggests she attach a bright red light to the rat's head to make it easy to track by computer - just find the reddest part in the red channel at each frame! Our post-doc does this, then collects more than 30 hours worth of data over two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with video data, have a new import today: `moviepy`. This is a library that helps you interact with movie files. Video file formats utilize lossy compression of some kind, but for something like a rat moving around, where we're not exactly trying to make quantitative measurements of photon counts, it's preferable to save space and take compression losses. Even for display in a paper's supplement, video formats like mp4 and mpeg are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy import editor as mpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vid_file_name = \"../data/rattrack.mp4\"\n",
    "vid = mpy.VideoFileClip(vid_file_name)\n",
    "mpy.ipython_display(vid, width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you begin processing this data to track the rat? What's our strategy going to be? What's different about this data compared to what we've seen before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the frames in the video, we will use the `VideoFileClip.get_frame(t)` function or `VideFileClip.iter_frames()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vid.get_frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vid.iter_frames?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the very first frame at time $t = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame = vid.get_frame(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a video in color. How many dimensions do we expect this frame to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, let's see if we can in fact find a red dot in a still frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just the red channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "red = frame[:,:,0]\n",
    "plt.imshow(red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks tractable! How might we grab the brightest point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = np.argmax(red)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this number mean? It turns out for that multidimensional arrays, `argmax` just tells you the position of the maximum value _if the array had first been flattened_. The brilliant minds behind Numpy know this probably isn't what you want, so they've provided you with `numpy.unravel_index`. It just needs to know the original array shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_index, column_index = np.unravel_index(index, red.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out we can help ourselves visualize that point by plotting directly on top of an image we made with imshow. `plt.plot` takes a list of $x$, $y$ values, and a style parameter (e.g. 'o' makes the points little circles) - it works exactly like Matlab's `plot` if you're familiar with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** how would you change the color of this pixel to make it stand out in the original color image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(frame)\n",
    "plt.plot(column_index, row_index, 'o')\n",
    "\n",
    "# Fix up the margins - plotting expands the plot area\n",
    "plt.xlim([0, frame.shape[1]])\n",
    "plt.ylim([frame.shape[0], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smooth\n",
    "# argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what?\n",
    "\n",
    "We need to do this for every frame in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_frames = vid.duration * vid.fps\n",
    "\n",
    "# a time x dim table. dim = 2 since we have 2D frames\n",
    "dot_position = np.zeros((num_frames, 2))\n",
    "\n",
    "for frame_num, frame in enumerate(vid.iter_frames()):\n",
    "    red = frame[:,:,0]\n",
    "    smooth = red# smoothing\n",
    "    peak = np.argmax(smooth)\n",
    "    position = np.unravel_index(peak, red.shape)\n",
    "    dot_position[frame_num, :] = position # set the whole row of the table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** How might you visualize how the rat is moving with time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two approaches to solving this: look at x and y position independently against time, or look at the path the animal takes through time. Both are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_position[:,0], dot_position[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at those jumps! We have a teleporting rat! Let's look at a time where the rat seems to teleport. Surely we are zeroing in on a major scientific discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jump_size = np.zeros(num_frames - 1)\n",
    "\n",
    "for t in range(0, int(num_frames - 1)):\n",
    "    jump_size[t] = np.sqrt(np.sum(np.square(dot_position[t+1,:] - dot_position[t,:])))\n",
    "    \n",
    "biggest_jump_t = np.argmax(jump_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "before = biggest_jump_t - 1\n",
    "after = biggest_jump_t\n",
    "ax[0].plot(dot_position[before,1], dot_position[before,0], 'o', fillstyle='none', markersize=20, markeredgewidth=5)\n",
    "ax[0].imshow(vid.get_frame((before)/ vid.fps))\n",
    "ax[1].plot(dot_position[after,1], dot_position[after,0], 'o', fillstyle='none', markersize=20, markeredgewidth=5)\n",
    "ax[1].imshow(vid.get_frame(after / vid.fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Time of biggest jump: {} seconds\".format(biggest_jump_t / vid.fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is happening at that time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toi = biggest_jump_t / vid.fps # TOI = time of interest\n",
    "short_clip = vid.subclip(toi - 1, toi + 2)\n",
    "mpy.ipython_display(short_clip, width=480, loop=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem seems to be that the animal has room to turn its head and occulude the light with its head or the wires it's attached to. In the period where the light is occluded we need to either guess that it doesn't move until we find it again, or use some other tracking mechanism. It's also potentially hard to tell when we lose the light - right now we just look for the brighest red pixel, which will always exist. In fact, a white pixel looks pretty bright in the red channel.\n",
    "\n",
    "Although there are some improvements we can make, it turns out that this problem went from very easy to very hard.\n",
    "\n",
    "That's because the real problem occured weeks ago, here: \"Collect some data --> Analyze said data\". Collecting and analyzing data are not separable steps. You should be building your data processing pipeline while you're building your experiment, and iterating on it as you're collecting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
