{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Pre-processing Part 1 - Global Thresholds\n",
    "\n",
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "In this module, you will\n",
    "- Review how to load digital images and associated metadata\n",
    "- Understand what it means to find a threshold for an image\n",
    "- Use a threshold to make a mask, i.e. separate the background and foreground of an image\n",
    "- Learn how to use Otsu's method to find threshold values\n",
    "- Understand the mechanics of Otsu's method, and learn its limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, a note about Jupyter notebooks for preprocessing pipelines:  \n",
    "\n",
    "They are great for the type of quick data visualization that you might want when developing an analysis pipeline. However, it's hard to build on notebooks or use functionalities in them between projects. For this reason, you may want to consider moving your most useful functions into scripts and working that way when looping through many types of data.  \n",
    "\n",
    "That said, few things as transparently demonstrate an analysis workflow, and they make wonderful supplements to the Materials sections of papers.  \n",
    "See http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261   \n",
    "https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks   \n",
    "notable example: http://nbviewer.jupyter.org/github/WagnerLabPapers/Waskom_JNeurosci_2014/blob/master/Behavioral_and_Decoding_Analyses.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today's project\n",
    "\n",
    "We will work with fluorescence microscopy data to characterize how vinculin contributes to cell spreading and focal adhesion formation. \n",
    "\n",
    "The signals that we will be looking at are phalloidin (F-actin), paxillin-EGFP (focal adhesion protein), and Heochst (nuclei). \n",
    "\n",
    "Hypothesis:\n",
    " - Preprocessing Part 1: Vinculin promotes cell spreading. The vinculin-null cells will have a spreading defect.\n",
    " - Preprocessing Part 2: Vinculin promotes focal adhesion formation. Vinculin-null cells will have fewer focal adhesions, smaller focal adhesions, or less focal total focal adhesion area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook settings and libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "     #keeps the plots that you display within the notebook\n",
    "\n",
    "#run me to import the libraries that you'll need for this exercise\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'})\n",
    "import matplotlib.axes as ax\n",
    "import scipy.ndimage\n",
    "\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'}) #this sets the default heatmap of images in \"imshow\" as the inferno heatmap (no more jet!))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your data directory to make loading and saving data later more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'insert path to data directory here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Load the WT and vincKO images into memory and report the dimensions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-864363e3d020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m \u001b[0;31m#import the imread function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwt_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"20170601-WT-DMSO-1.tif\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mwt_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwt_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "#run me to load data needed for the exercise\n",
    "from skimage.io import imread #import the imread function\n",
    "\n",
    "wt_filename = data_path + \"20170601-WT-DMSO-1.tif\"\n",
    "wt_data = imread(wt_filename)\n",
    "\n",
    "vinc_filename = data_path + \"20170601-vincKO-DMSO-1.tif\"\n",
    "vinc_data = imread(vinc_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the metadata:   \n",
    "Here I have saved the metadata in a file format called json. Json files are easily loaded into python as the dictionary data type. Dictionaries in python are indexed with keys, which are strings instead of numerical indices (such as used in lists). To understand this concept, load the below json file and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba880f0a5d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#run me to import the metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"20170601-vincKO-DMSO-1.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetadata_wt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmeta_wt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_wt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "#run me to import the metadata\n",
    "import json\n",
    "with open(data_path + \"20170601-vincKO-DMSO-1.json\", mode='r') as metadata_wt:\n",
    "    meta_wt = json.load(metadata_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at the contents of meta_wt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to organize your data into a dict instead of a numerical array when one of the dimensions of the array corresponds to something that is non-numerical in nature. Here, the channel dimension is stored as another dimension in the numerical array that is wt_data. To get the image corresponding to one of the channels, you would have to remember which of the channel slices corresponds to the channel you would like to see. Below we'll organize the data into a dict so that the channels can be indexed by an intuitive string and not a numerical index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run me to organize the data into a dictionary, where the channels can be indexed with a string  \n",
    "wt = {}\n",
    "vinc = {}\n",
    "\n",
    "for idx, channel in enumerate(meta_wt['channels']):\n",
    "    wt[channel] = wt_data[:,:,idx]\n",
    "    vinc[channel] = vinc_data[:,:,idx] #add in the indexing when read in full dataset\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Set the wild type actin slice to the variable \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-af9df1cded08>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-af9df1cded08>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    data =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-04bb6dd5b2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#visualize all data simultaneously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"actin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nucleus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pax\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6cAAAECCAYAAAACUqEEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1176894a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize all data simultaneously\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(wt[\"actin\"])\n",
    "ax[1].imshow(wt['nucleus'])\n",
    "ax[2].imshow(wt[\"pax\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(vinc[\"actin\"])\n",
    "ax[1].imshow(vinc['nucleus'])\n",
    "ax[2].imshow(vinc[\"pax\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Use imshow to zoom in on a small section of the pax images to examine the small structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing: a motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: write a function that has the following attributes: \n",
    "- Input: numerical threshold and input image\n",
    "- Output: visualization of the the images binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Determine a global threshold for the nucleus channel of both images. Discuss what is preventing this from working robustly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = vinc[\"actin\"]\n",
    "data2 = wt[\"actin\"]\n",
    "\n",
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_masks(thresh=(0, data1.max() * 0.3, 40)):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(64, 16))\n",
    "    mask1 = np.zeros(data1.shape)\n",
    "    mask2 = np.zeros(data2.shape)\n",
    "    \n",
    "    mask1[data1 >=thresh] = 1\n",
    "    mask2[data2 >=thresh] = 1\n",
    "    \n",
    "    ax[0].imshow(mask1, vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask2, vmin=0, vmax=1)\n",
    "show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will define the ROIs in this set of images. You may have noticed some qualities of the above images that make them hard to reliably threshold into masks relecting the relevant cell organelles.\n",
    "\n",
    "Addressed in Preprocessing part 1:\n",
    "1. There appears to be some variation in the background and intensity between actin datasets. Perhaps there was some variability in the focus when the image was taken, someone opened the microscope room door during imaging of one of the datasets, pipetting error when staining, or that some of the cells really do have more actin. \n",
    "    - automated statistical thresholding methods\n",
    "    \n",
    "Addressed preprocessing part 2:\n",
    "2. Noise corrupting the images\n",
    "    - Introduction to Rank Filters: median filter\n",
    "2. Uneven illumination in the nucleus channel makes finding a single threshold across a single image challenging. \n",
    "    - Rolling ball background subtraction\n",
    "3. Uneven paxillin expression, low EGFP signal, and cytoplasmic signal complicate focal adhesion thresholding\n",
    "    - thresholding within defined ROIs\n",
    "    \n",
    "Addressed in Morphological Operations:\n",
    "4. Small blobs appear in nuclear mask, making it hard to count nuclei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: View the histogram of pixel values for the nucleus dataset. Does Otsu's method make sense? Perform Otsu's thresholding on the nucleus dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#you can use seaborn's distplot with fewer arguments than I used. This can be a one-line exercise\n",
    "#you may need to use the \"flatten\" function.\n",
    "#if you are stumped, look up the documentation on both.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Determine what is incorrect about the application of Otsu's method below (there are two independent errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "thresh = filters.threshold_li(data)\n",
    "print(\"the Otsu masking threshold for this dataset is:\", thresh)\n",
    "\n",
    "mask = np.zeros(data.shape)\n",
    "mask[data <=thresh] = 1\n",
    "\n",
    "plt.imshow(mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Otsu's method performs sub-optimally in this case because of the distribution of background and foreground values. \n",
    "Find the documentation for the scipy filter options and determine if another thresholding algorithm would be more appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_masks = {}\n",
    "vinc_masks = {}\n",
    "\n",
    "for ch in wt:\n",
    "    wt_masks[ch] = mask_im(wt[ch], filters.threshold_otsu(wt[ch]))\n",
    "    vinc_masks[ch] = mask_im(vinc[ch], filters.threshold_otsu(vinc[ch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing 2: Rank filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
