{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Pre-processing Part 1 - Global Thresholds\n",
    "\n",
    "Fluorescence datasets ideally reflect a relationship between the pixels in an image and the location and local density of your fluorescent molecule in a sample. However, properties of the detectors, optics, or even the samples can confound direct interpretation of this data. Here we will present some operations that can mitigate these effects to achieve robust hypothesis testing. \n",
    "\n",
    "In this module, you will\n",
    "- Review how to load digital images and associated metadata\n",
    "- Understand what it means to find a threshold for an image\n",
    "- Use a threshold to make a mask, i.e. separate the background and foreground of an image\n",
    "- Learn how to use Otsu's method to find threshold values\n",
    "- Understand the mechanics of Otsu's method, and learn its limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, a note about Jupyter notebooks for preprocessing pipelines:  \n",
    "\n",
    "They are great for the type of quick data visualization that you might want when developing an analysis pipeline. However, it's hard to build on notebooks or use functionalities in them between projects. For this reason, you may want to consider moving your most useful functions into scripts and working that way when looping through many types of data.  \n",
    "\n",
    "That said, few things as transparently demonstrate an analysis workflow, and they make wonderful supplements to the Materials sections of papers.  \n",
    "See http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261   \n",
    "https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks   \n",
    "notable example: http://nbviewer.jupyter.org/github/WagnerLabPapers/Waskom_JNeurosci_2014/blob/master/Behavioral_and_Decoding_Analyses.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today's project\n",
    "\n",
    "We will work with fluorescence microscopy data to characterize how vinculin contributes to cell spreading and focal adhesion formation. \n",
    "\n",
    "The signals that we will be looking at are phalloidin (F-actin), paxillin-EGFP (focal adhesion protein), and Heochst (nuclei). \n",
    "\n",
    "Hypothesis:\n",
    " - Preprocessing Part 1: Vinculin promotes cell spreading. The vinculin-null cells will have a spreading defect.\n",
    " - Preprocessing Part 2: Vinculin promotes focal adhesion formation. Vinculin-null cells will have fewer focal adhesions, smaller focal adhesions, or less focal total focal adhesion area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook settings and libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "     #keeps the plots that you display within the notebook\n",
    "\n",
    "#run me to import the libraries that you'll need for this exercise\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.io import imread\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'})\n",
    "import matplotlib.axes as ax\n",
    "import scipy.ndimage\n",
    "\n",
    "sns.set_style('dark', rc={'image.cmap':'inferno'}) #this sets the default heatmap of images in \"imshow\" as the inferno heatmap (no more jet!))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your data directory to make loading and saving data later more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'insert path to data directory here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Load the WT and vincKO images into memory and report the dimensions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run me to load data needed for the exercise\n",
    "from skimage.io import imread #import the imread function\n",
    "\n",
    "wt_filename = data_path + \"20170601-WT-DMSO-1.tif\"\n",
    "wt_data = imread(wt_filename)\n",
    "\n",
    "vinc_filename = data_path + \"20170601-vincKO-DMSO-1.tif\"\n",
    "vinc_data = imread(vinc_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the metadata:   \n",
    "Here I have saved the metadata in a file format called json. Json files are easily loaded into python as the dictionary data type. Dictionaries in python are indexed with keys, which are strings instead of numerical indices (such as used in lists). To understand this concept, load the below json file and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run me to import the metadata\n",
    "import json\n",
    "with open(data_path + \"20170601-vincKO-DMSO-1.json\", mode='r') as metadata_wt:\n",
    "    meta_wt = json.load(metadata_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at the contents of meta_wt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to organize your data into a dict instead of a numerical array when one of the dimensions of the array corresponds to something that is non-numerical in nature. Here, the channel dimension is stored as another dimension in the numerical array that is wt_data. To get the image corresponding to one of the channels, you would have to remember which of the channel slices corresponds to the channel you would like to see. Below we'll organize the data into a dict so that the channels can be indexed by an intuitive string and not a numerical index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run me to organize the data into a dictionary, where the channels can be indexed with a string  \n",
    "wt = {}\n",
    "vinc = {}\n",
    "\n",
    "for idx, channel in enumerate(meta_wt['channels']):\n",
    "    wt[channel] = wt_data[:,:,idx]\n",
    "    vinc[channel] = vinc_data[:,:,idx] #add in the indexing when read in full dataset\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Set the wild type actin slice to the variable \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images to make sure everything worked as expected..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#visualize all data simultaneously\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(wt[\"actin\"])\n",
    "ax[1].imshow(wt['nucleus'])\n",
    "ax[2].imshow(wt[\"pax\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(vinc[\"actin\"])\n",
    "ax[1].imshow(vinc['nucleus'])\n",
    "ax[2].imshow(vinc[\"pax\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Use imshow to zoom in on a small section of the pax images to examine the small structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image pre-processing: a motivating example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will define the ROIs in the image. We'll find that the quality of masks can be improved by preprocessing the images by quantitatively determining thresholds and filtering to remove noise. We will then cover how to clean up the mask and turn it into an accurate ROI using morphological image processing. \n",
    "\n",
    "**Preprocessing misteps are a good way to get a paper retracted. We argue that it's easier to make these misteps when doing things manually, but it's not *impossible* to do it computationally. In fact if you don't check intermediate steps of your data in either case, it's no good. Always visualize your intermediates!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: write a function that has the following attributes: \n",
    "- Input: numerical threshold and input image\n",
    "- Output: visualization of the the images binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Determine a global threshold for the nucleus channel of both images. Discuss what is preventing this from working robustly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = vinc[\"actin\"]\n",
    "data2 = wt[\"actin\"]\n",
    "\n",
    "from ipywidgets import interactive\n",
    "@interactive\n",
    "def show_masks(thresh=(0, data1.max() * 0.3, 40)):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(64, 16))\n",
    "    mask1 = np.zeros(data1.shape)\n",
    "    mask2 = np.zeros(data2.shape)\n",
    "    \n",
    "    mask1[data1 >=thresh] = 1\n",
    "    mask2[data2 >=thresh] = 1\n",
    "    \n",
    "    ax[0].imshow(mask1, vmin=0, vmax=1)\n",
    "    ax[1].imshow(mask2, vmin=0, vmax=1)\n",
    "show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will define the ROIs in this set of images. You may have noticed some qualities of the above images that make them hard to reliably threshold into masks relecting the relevant cell organelles.\n",
    "\n",
    "Addressed in Preprocessing part 1:\n",
    "1. There appears to be some variation in the background and intensity between actin datasets. Perhaps there was some variability in the focus when the image was taken, someone opened the microscope room door during imaging of one of the datasets, pipetting error when staining, or that some of the cells really do have more actin. \n",
    "    - automated statistical thresholding methods\n",
    "    \n",
    "Addressed preprocessing part 2:\n",
    "2. Noise corrupting the images\n",
    "    - Introduction to Rank Filters: median filter\n",
    "2. Uneven illumination in the nucleus channel makes finding a single threshold across a single image challenging. \n",
    "    - Rolling ball background subtraction\n",
    "3. Uneven paxillin expression, low EGFP signal, and cytoplasmic signal complicate focal adhesion thresholding\n",
    "    - thresholding within defined ROIs\n",
    "    \n",
    "Addressed in Morphological Operations:\n",
    "4. Small blobs appear in nuclear mask, making it hard to count nuclei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: View the histogram of pixel values for the nucleus dataset. Does Otsu's method make sense? Perform Otsu's thresholding on the nucleus dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#you can use seaborn's distplot with fewer arguments than I used. This can be a one-line exercise\n",
    "#you may need to use the \"flatten\" function.\n",
    "#if you are stumped, look up the documentation on both.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Determine what is incorrect about the application of Otsu's method below (there are two independent errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "thresh = filters.threshold_li(data)\n",
    "print(\"the Otsu masking threshold for this dataset is:\", thresh)\n",
    "\n",
    "mask = np.zeros(data.shape)\n",
    "mask[data <=thresh] = 1\n",
    "\n",
    "plt.imshow(mask_zoom_edge, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Otsu's method performs sub-optimally in this case because of the distribution of background and foreground values. \n",
    "Find the documentation for the scipy filter options and determine if another thresholding algorithm would be more appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wt_masks = {}\n",
    "vinc_masks = {}\n",
    "\n",
    "for ch in wt:\n",
    "    wt_masks[ch] = mask_im(wt[ch], filters.threshold_otsu(wt[ch]))\n",
    "    vinc_masks[ch] = mask_im(vinc[ch], filters.threshold_otsu(vinc[ch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing 2: Rank filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lesson 4: Pre-processing Part 2 - Rank Filters\n",
    "\n",
    "Here we continue from Pre-processing Part 1, and introduce the following concepts\n",
    "- The limits of Otsu's method to find global thresholds\n",
    "- The difference between global and local processing methods\n",
    "- A few useful local pre-processing operations\n",
    "    - Using the median filter to remove noise\n",
    "    - Using rolling ball background subtraction\n",
    "- The effect of varying the structuring element on rank filters\n",
    "- How to obtain useful global metrics from processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(wt_masks[\"actin\"])\n",
    "ax[1].imshow(wt_masks['nucleus'])\n",
    "ax[2].imshow(wt_masks[\"pax\"])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "ax[0].imshow(vinc_masks[\"actin\"])\n",
    "ax[1].imshow(vinc_masks['nucleus'])\n",
    "ax[2].imshow(vinc_masks[\"pax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zoom_mask_visualization(image, mask, max_val_see, crop_values):\n",
    "    \"\"\"zoom_mask_visualization(image, mask, max_val_see, crop_values)\n",
    "    max_val_see sets the contrast. Small values will make the image appear brighter\n",
    "    crop_values is a list formatted as [ymin, ymax, xmin, xmax] for choosing the window to visualize\"\"\"\n",
    "    \n",
    "    if len(crop_values) !=4:\n",
    "        return print('format crop values as [ymin, ymax, xmin, xmax]')\n",
    "    \n",
    "    [ymin, ymax, xmin, xmax] = crop_values\n",
    "    \n",
    "    if ymin >= ymax:\n",
    "        return print('ymin must 0<ymin<ymax. Format crop_values as [ymin, ymax, xmin, xmax]')\n",
    "    elif xmin >= xmax:\n",
    "        print('xmin must 0<xmin<xmax. Format crop_values as [ymin, ymax, xmin, xmax]')\n",
    "        return\n",
    "    elif xmax > image.shape[1]:\n",
    "        print('xmax must be smaller than the width of the image in pixels')\n",
    "        return\n",
    "    elif ymax > image.shape[1]:\n",
    "        print('xmax must be smaller than the width of the image in pixels')\n",
    "        return\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(64, 50))\n",
    "    ax[0].imshow(image[ymin:ymax,xmin:xmax],interpolation='none',vmin=0, vmax=max_val_see)\n",
    "    ax[1].imshow(mask[ymin:ymax,xmin:xmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crop_values = [700,900,700,900]\n",
    "max_val_see = 3000\n",
    "image = wt['pax']\n",
    "mask = wt_masks['pax']\n",
    "zoom_mask_visualization(image, mask, max_val_see, crop_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note the problems with the dataset that produce low-quality ROIs:\n",
    "1) Noise\n",
    "2) Uneven illumination\n",
    "\n",
    "Rank filters are a subset of common image processing tools that modify images pixel-by-pixel by including information about the surrounding pixels. They do the heavy lifting in many algorithms for denoising (here the median filter), flattening illumination or background, and morphological manipulations. \n",
    "\n",
    "The skimage piece on rank filters (http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_rank_filters.html#sphx-glr-auto-examples-xx-applications-plot-rank-filters-py) explains different types of filters and has sample code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise: choose a small window of one of the pax images to use as your sample dataset for the remainder of the lesson. Set this to the variable *data*. I recommend a 25x25 pixel window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_noised = #add whatever type of noise you would like to this sample dataset, including a few dead pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extreme = 1000\n",
    "\n",
    "from skimage.filters.rank import median as median_filter\n",
    "from ipywidgets import interactive\n",
    "im_filter = data_noised\n",
    "\n",
    "@interactive\n",
    "def apply_filter(s=(1,10)):\n",
    "    # Here we implement the median filtering\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    ax[0].imshow(im_filter, interpolation = 'none')\n",
    "    ax[0].set_title('original')\n",
    "    filtered = median_filter(im_filter, disk(s))\n",
    "    dif_img = filtered.astype('int') - im_filter.astype('int')\n",
    "    print(\"total difference in image =\" + str(np.mean(dif_img)) + \" arbitrary units\")\n",
    "    print(\"percent change =\" + str(np.mean(dif_img)/100) + \"%\")                     \n",
    "    ax[1].imshow(filtered, interpolation = 'none')\n",
    "    ax[1].set_title('filtered with s = {0:d}'.format(s))\n",
    "    ax[2].imshow(dif_img, vmin=-extreme, vmax=extreme, cmap='coolwarm',interpolation = 'none')\n",
    "    ax[2].set_title('difference between images')\n",
    "apply_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise: Match the output image to the operation that produced it (from a single input image)\n",
    "\n",
    "Match the sample figure to the type of operation performed on it (with a disk structuring element):\n",
    "\n",
    "    1) Mean filter, s=10\n",
    "    2) Min filter, s=10\n",
    "    3) Max filter, s=10\n",
    "    4) Mean filter, s=2\n",
    "    5) Min filter, s=2\n",
    "    6) Max filter, s=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read image\n",
    "img = imread(data_path+\"/raw_for_types_of_filters_exercise.png\")\n",
    "\n",
    "# image preprocessing\n",
    "from skimage.filters.rank import mean as mean_filter\n",
    "from skimage.filters.rank import minimum as min_filter\n",
    "from skimage.filters.rank import maximum as max_filter\n",
    "\n",
    "max_view = 50000\n",
    "s_small = 2\n",
    "s_large = 10\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(64, 32))\n",
    "ax[0, 0].imshow(mean_filter(img, disk(s_large)), interpolation = 'none', vmin = 0, vmax = max_view)\n",
    "ax[0, 1].imshow(min_filter(img, disk(s_large)), interpolation = 'none', vmin = 0, vmax = max_view)\n",
    "ax[0, 2].imshow(max_filter(img, disk(s_large)), interpolation = 'none', vmin = 0, vmax = max_view)\n",
    "ax[1, 0].imshow(mean_filter(img, disk(s_small)), interpolation = 'none', vmin = 0, vmax = max_view)\n",
    "ax[1, 1].imshow(min_filter(img, disk(s_small)), interpolation = 'none', vmin = 0, vmax = max_view)\n",
    "ax[1, 2].imshow(max_filter(img, disk(s_small)), interpolation = 'none', vmin = 0, vmax = max_view)\n",
    "\n",
    "ax[0, 0].set_title('Mean fitler, s = ' + str(s_large))\n",
    "ax[0, 1].set_title('Min fitler, s = ' + str(s_large))\n",
    "ax[0, 2].set_title('Max fitler, s = ' + str(s_large))\n",
    "ax[1, 0].set_title('Mean fitler, s = ' + str(s_small))\n",
    "ax[1, 1].set_title('Min fitler, s = ' + str(s_small))\n",
    "ax[1, 2].set_title('Max fitler, s = ' + str(s_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Filters Example 2: Rolling Ball Background Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about how to improve the masking of the nuclear dataset. If you carefully examine the nucleus images with a lot of brightness, you'll see that the brightness across the image looks pretty different - highest in the lower right corner and decreasing towards the upper left. This could occur from something like abberations in the light path, or the sample being a little tilted in the sample holder during imaging. Also note that the cytoplasm is somewhat fluorescent, which further confounds the thresholding algorithms.\n",
    "\n",
    "One way to improve the separation of the foreground and background might be to apply a *local background subtraction*. How might we do this? \n",
    "*hint* use a large min filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_ball_sub(raw_im, r):\n",
    "    \"\"\"r is the radius of the structuring element used to calculate the background\"\"\"\n",
    "    bg = min_filter(raw_im, disk(r))\n",
    "    bgs = raw_im - bg\n",
    "    plt.imshow(bgs)\n",
    "    return bgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Discuss how you might use rolling background subtraction to generate images of the paxillin channel to threshold the focal adhesions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Examine the background for the  image below, which has been corrupted with salt and pepper noise. Why might the min filter fail in this case, and what might you do to correct it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "your_image = vinc['actin'] #fill me in with something you'd like to use in the exercise\n",
    "dim1, dim2 = your_image.shape\n",
    "your_image[10, 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg = min_filter(your_image,disk(21))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
